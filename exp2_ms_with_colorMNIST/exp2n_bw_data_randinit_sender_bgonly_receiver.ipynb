{"cells":[{"cell_type":"markdown","id":"46e81ec0-e3c4-4060-97c1-bfccf47bc350","metadata":{"id":"46e81ec0-e3c4-4060-97c1-bfccf47bc350"},"source":["## exp 2n bw data through randinit network to bgonly receiver (like in exp2e_d but without training the sender)\n","bg_unbiased means digit and bg_colour are unrelated, but the model is trained and tested on the background.\n","\n","bg_colour will be varied by 10% in each channel\n","\n","In the original exp2e, all stitches were trained on the bias dataset. In this version, the stitch is trained on the dataset used to train the sender model. Hardcoded this test to only stitch bw to itself and colour-only to itself\n","\n","Try the different sender networks at all different stitch levels\n","\n","## Rank\n","Also perform rank analysis on the stitched networks based on exp1e\n","## 4 Epochs\n","Only do 4 epochs of training (keep 10 epochs of stitch training) so that the initial models are weaker\n","## Consistency - set train_all to False and use the original trained networks"]},{"cell_type":"code","source":["from google.colab import files\n","\n","#uploaded = files.upload()"],"metadata":{"id":"SoqxVQhqnkuz","executionInfo":{"status":"ok","timestamp":1747511970246,"user_tz":-60,"elapsed":22,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"id":"SoqxVQhqnkuz","execution_count":7,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvvym2owW-WW","executionInfo":{"status":"ok","timestamp":1747511971291,"user_tz":-60,"elapsed":1050,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}},"outputId":"e5d78609-cbe8-4da4-8606-be5d1669f712"},"id":"qvvym2owW-WW","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install torchbearer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufnM5LLkadX9","executionInfo":{"status":"ok","timestamp":1747511974324,"user_tz":-60,"elapsed":3037,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}},"outputId":"9a4937f9-6802-4271-9945-4143d6a1ea40"},"id":"ufnM5LLkadX9","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchbearer in /usr/local/lib/python3.11/dist-packages (0.5.5)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchbearer) (2.6.0+cu124)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchbearer) (2.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchbearer) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchbearer) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->torchbearer) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->torchbearer) (3.0.2)\n"]}]},{"cell_type":"code","execution_count":10,"id":"51fc60f8-f6f6-469c-8705-c9015bd43951","metadata":{"id":"51fc60f8-f6f6-469c-8705-c9015bd43951","executionInfo":{"status":"ok","timestamp":1747511974374,"user_tz":-60,"elapsed":53,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"outputs":[],"source":["# Packages\n","%matplotlib inline\n","\n","drive_path = '/content/drive/MyDrive/Colab Notebooks/icml'\n","import os\n","#os.chdir('/content/drive')\n","#print(os.listdir(drive_path))\n","os.chdir(drive_path)\n","import argparse\n","import gc\n","import os.path\n","\n","import pandas as pd\n","from torch.linalg import LinAlgError\n","\n","import matplotlib.pyplot as plt\n","import torchvision\n","import torch\n","from torch import optim\n","\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import MNIST\n","import torchvision.transforms as transforms\n","import datetime\n","\n","import random\n","import numpy as np\n","\n","import sys\n","import os\n","# add the path to find colour_mnist\n","#sys.path.append(os.path.abspath('./ICML/ReferenceCode'))\n","import colour_mnist\n","from stitch_utils import train_model, RcvResNet18, StitchedResNet18, get_layer_output_shape\n","from stitch_utils import generate_activations, SyntheticDataset\n","import stitch_utils\n","\n","# add the path to find the rank analysis code\n","# https://github.com/DHLSmith/jons-tunnel-effect/tree/NeurIPSPaper\n","#sys.path.append(os.path.abspath('../../jons-tunnel-effect/'))\n","from utils.modelfitting import evaluate_model, set_seed\n","from extract_weight_rank import install_hooks, perform_analysis\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.datasets import MNIST\n","\n","# To track memory usage\n","import psutil\n","process = psutil.Process()\n","\n","\n","def logtofile(log_text, verbose=True):\n","    if verbose:\n","        print(log_text)\n","    with open(save_log_as, \"a\") as f:\n","        print(log_text, file=f)"]},{"cell_type":"code","execution_count":11,"id":"6761870b-2996-4763-8d90-76529ec5822e","metadata":{"id":"6761870b-2996-4763-8d90-76529ec5822e","executionInfo":{"status":"ok","timestamp":1747511974388,"user_tz":-60,"elapsed":12,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"outputs":[],"source":["# Set Parameters\n","\n","# fix random seed for reproducibility\n","seed = 10\n","torch.manual_seed(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","random.seed(seed)\n","torch.cuda.manual_seed(seed)\n","np.random.seed(seed)\n","save_stitch_delta = False\n","measure_rank = False\n","\n","results_root = \"results_2n\"\n","\n","# randinit model\n","gen_randinit_model = False\n","# from exp 2m\n","randinit_model_to_load = f\"./2025-03-26_12-06-31_SEED57_EPOCHS4_BGN0.1_exp2e_ResNet18_randinit.weights\"\n","\n","# BW is greyscale mnist with no colour added\n","train_bw_mnist_model = False  # when False, automatically loads a trained model\n","# from results_4_epochs\n","bw_mnist_model_to_load = './2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bw_mnist.weights'\n","\n","# BG_ONLY contains no mnist data, just a coloured background\n","train_bg_only_colour_mnist_model = False  # when False, automatically loads a trained model\n","bg_only_colour_mnist_model_to_load =  \"./2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist.weights\"\n","\n","original_train_epochs = 4\n","bg_noise = 0.1\n","\n","stitch_train_epochs = 10\n","\n","batch_size = 128"]},{"cell_type":"code","execution_count":12,"id":"20ee6e98-a6f2-4647-b378-5f7b1af48581","metadata":{"id":"20ee6e98-a6f2-4647-b378-5f7b1af48581","outputId":"161a2236-f9af-4605-842e-94c80b68a9c1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747511974447,"user_tz":-60,"elapsed":63,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Executed at 2025-05-17_19-59-33\n","logging to ./results_2n/2025-05-17_19-59-33_SEED10_EPOCHS4_BGN0.1_exp2e_ResNet18_log.txt\n","seed=10\n","bg_noise=0.1\n","gen_randinit_model=False\n","randinit_model_to_load='./2025-03-26_12-06-31_SEED57_EPOCHS4_BGN0.1_exp2e_ResNet18_randinit.weights'\n","train_bw_mnist_model=False\n","bw_mnist_model_to_load='./2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bw_mnist.weights'\n","train_bg_only_colour_mnist_model=False\n","bg_only_colour_mnist_model_to_load='./2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist.weights'\n","stitch_train_epochs=10\n","================================================\n"]}],"source":["# Generate filenames and log the setup details\n","formatted_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n","filename_prefix = f\"./{results_root}/{formatted_time}_SEED{seed}_EPOCHS{original_train_epochs}_BGN{bg_noise}_exp2e_ResNet18\"\n","save_mix_mnist_model_as = f\"{filename_prefix}_mix_mnist.weights\"\n","save_bw_mnist_model_as = f\"{filename_prefix}_bw_mnist.weights\"\n","save_bg_only_colour_mnist_model_as = f\"{filename_prefix}_bg_only_colour_mnist.weights\"\n","save_bg_unbiased_colour_mnist_model_as = f\"{filename_prefix}_bg_unbiased_colour_mnist.weights\"\n","save_biased_colour_mnist_model_as = f\"{filename_prefix}_biased_colour_mnist.weights\"\n","save_unbiased_colour_mnist_model_as = f\"{filename_prefix}_unbiased_colour_mnist.weights\"\n","save_randinit_model_as = f\"{filename_prefix}_randinit.weights\"\n","save_log_as = f\"{filename_prefix}_log.txt\"\n","\n","colour_mnist_shape = (3,28,28)\n","\n","\n","logtofile(f\"Executed at {formatted_time}\")\n","logtofile(f\"logging to {save_log_as}\")\n","logtofile(f\"{seed=}\")\n","logtofile(f\"{bg_noise=}\")\n","\n","\n","logtofile(f\"{gen_randinit_model=}\")\n","if gen_randinit_model:\n","    logtofile(f\"{save_randinit_model_as=}\")\n","else:\n","    logtofile(f\"{randinit_model_to_load=}\")\n","\n","\n","logtofile(f\"{train_bw_mnist_model=}\")\n","if train_bw_mnist_model:\n","    logtofile(f\"{save_bw_mnist_model_as=}\")\n","    logtofile(f\"{original_train_epochs=}\")\n","else:\n","    logtofile(f\"{bw_mnist_model_to_load=}\")\n","\n","logtofile(f\"{train_bg_only_colour_mnist_model=}\")\n","if train_bg_only_colour_mnist_model:\n","    logtofile(f\"{save_bg_only_colour_mnist_model_as=}\")\n","    logtofile(f\"{original_train_epochs=}\")\n","else:\n","    logtofile(f\"{bg_only_colour_mnist_model_to_load=}\")\n","\n","\n","logtofile(f\"{stitch_train_epochs=}\")\n","logtofile(f\"================================================\")"]},{"cell_type":"markdown","id":"6cc621f6-55e8-4191-8288-dc2493cd6bff","metadata":{"id":"6cc621f6-55e8-4191-8288-dc2493cd6bff"},"source":["mnist and cifar-10 both use 10-classes, with 60_000 train samples and 10_000 test samples."]},{"cell_type":"code","execution_count":13,"id":"d34a54d2-c8fa-4f51-8809-7a40b4fefc6c","metadata":{"id":"d34a54d2-c8fa-4f51-8809-7a40b4fefc6c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747511983026,"user_tz":-60,"elapsed":8578,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}},"outputId":"c0248ab3-f84c-4752-f9e9-254398d6d46d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}],"source":["# Set up dataloaders\n","transform_bw = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=3),  # Convert to 3 channels\n","    transforms.ToTensor(),  # convert to tensor. We always do this one\n","    transforms.Normalize((0.1307,) * 3, (0.3081,) * 3)\n","])\n","\n","mnist_train = MNIST(\"./MNIST\", train=True, download=True, transform=transform_bw)\n","mnist_test = MNIST(\"./MNIST\", train=False, download=True, transform=transform_bw)\n","\n","bw_train_dataloader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","bw_test_dataloader  = DataLoader(mnist_test,  batch_size=batch_size, shuffle=True, drop_last=False)\n","\n","# mix dataloader\n","#mix_train_dataloader = colour_mnist.get_mixed_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size, train=True, bg_noise_level=bg_noise, standard_getitem=True)\n","#mix_test_dataloader = colour_mnist.get_mixed_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size,  train=False, bg_noise_level=bg_noise, standard_getitem=True)\n","\n","# bg_only means no digits - we will use colour as label\n","bg_only_train_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size, data_label_correlation=1.0, train=True, bg_noise_level=bg_noise, bg_only=True, standard_getitem=True)\n","bg_only_test_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size, data_label_correlation=1.0, train=False, bg_noise_level=bg_noise, bg_only=True, standard_getitem=True)\n","\n","# unbiased means each digit has correct label and random colour - but bg means we will use colour as label (i.e. the bias_target will be the target)\n","#bg_unbiased_train_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size, data_label_correlation=0.1, train=True, bg_noise_level=bg_noise, bias_targets_as_targets=True)\n","#bg_unbiased_test_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size, data_label_correlation=0.1, train=False, bg_noise_level=bg_noise, bias_targets_as_targets=True)\n","\n","# biased means each digit has correct label and consistent colour - Expect network to learn the colours only\n","#biased_train_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size, data_label_correlation=1.0, train=True, bg_noise_level=bg_noise, standard_getitem=True)\n","#biased_test_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size, data_label_correlation=1.0, train=False, bg_noise_level=bg_noise, standard_getitem=True)\n","\n","# unbiased means each digit has correct label and random colour - Expect network to disregard colours?\n","#unbiased_train_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size, data_label_correlation=0.1, train=True, bg_noise_level=bg_noise, standard_getitem=True)\n","#unbiased_test_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=batch_size, data_label_correlation=0.1, train=False, bg_noise_level=bg_noise, standard_getitem=True)"]},{"cell_type":"markdown","id":"24842d82-5f62-4d1b-acc5-d1997a08b0b9","metadata":{"id":"24842d82-5f62-4d1b-acc5-d1997a08b0b9"},"source":["## Set up resnet18 models and train it on versions of MNIST"]},{"cell_type":"code","execution_count":14,"id":"cf635cfd-a9ad-4e37-98a0-80d0db2a3b9f","metadata":{"id":"cf635cfd-a9ad-4e37-98a0-80d0db2a3b9f","outputId":"df9b9947-d77b-438d-ead8-39db786d6d1c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747511992774,"user_tz":-60,"elapsed":9697,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing for key='bw'\n","val['loadfrom']='./2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bw_mnist.weights'\n","Processing for key='bgonly'\n","val['loadfrom']='./2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist.weights'\n","Processing for key='randinit'\n","val['loadfrom']='./2025-03-26_12-06-31_SEED57_EPOCHS4_BGN0.1_exp2e_ResNet18_randinit.weights'\n"]}],"source":["\n","\n","process_structure = dict()\n","device = 'cuda'\n","\n","\n","# process_structure[\"mix\"] = dict()\n","process_structure[\"bw\"] = dict()\n","process_structure[\"bgonly\"] = dict()\n","process_structure[\"randinit\"] = dict()\n","# process_structure[\"bg\"] = dict()\n","# process_structure[\"bias\"]      = dict()\n","# process_structure[\"unbias\"]    = dict()\n","\n","# \"randinit\"\n","process_structure[\"randinit\"][\"model\"] = torchvision.models.resnet18(num_classes=10).to(device) # Untrained model\n","process_structure[\"randinit\"][\"train\"] = gen_randinit_model\n","process_structure[\"randinit\"][\"train_loader\"] = None\n","process_structure[\"randinit\"][\"test_loader\"] = bw_test_dataloader  # Use bw Test as that's what the main test will use\n","process_structure[\"randinit\"][\"saveas\"] = save_randinit_model_as\n","process_structure[\"randinit\"][\"loadfrom\"] = randinit_model_to_load\n","\n","# \"mix\"\n","# process_structure[\"mix\"][\"model\"] = torchvision.models.resnet18(num_classes=10).to(device) # Untrained model\n","# process_structure[\"mix\"][\"train\"] = train_mix_mnist_model\n","# process_structure[\"mix\"][\"train_loader\"] = mix_train_dataloader\n","# process_structure[\"mix\"][\"test_loader\"] = mix_test_dataloader\n","# process_structure[\"mix\"][\"saveas\"] = save_mix_mnist_model_as\n","# process_structure[\"mix\"][\"loadfrom\"] = mix_mnist_model_to_load\n","\n","# \"bw\"\n","process_structure[\"bw\"][\"model\"] = torchvision.models.resnet18(num_classes=10).to(device) # Untrained model\n","process_structure[\"bw\"][\"train\"] = train_bw_mnist_model\n","process_structure[\"bw\"][\"train_loader\"] = bw_train_dataloader\n","process_structure[\"bw\"][\"test_loader\"] = bw_test_dataloader\n","process_structure[\"bw\"][\"saveas\"] = save_bw_mnist_model_as\n","process_structure[\"bw\"][\"loadfrom\"] = bw_mnist_model_to_load\n","\n","# \"bg_only_colour\"\n","process_structure[\"bgonly\"][\"model\"] = torchvision.models.resnet18(num_classes=10).to(device) # Untrained model\n","process_structure[\"bgonly\"][\"train\"] = train_bg_only_colour_mnist_model\n","process_structure[\"bgonly\"][\"train_loader\"] = bg_only_train_dataloader\n","process_structure[\"bgonly\"][\"test_loader\"] = bg_only_test_dataloader\n","process_structure[\"bgonly\"][\"saveas\"] = save_bg_only_colour_mnist_model_as\n","process_structure[\"bgonly\"][\"loadfrom\"] = bg_only_colour_mnist_model_to_load\n","\n","# \"bg_unbiased_colour\"\n","# process_structure[\"bg\"][\"model\"] = torchvision.models.resnet18(num_classes=10).to(device) # Untrained model\n","# process_structure[\"bg\"][\"train\"] = train_bg_unbiased_colour_mnist_model\n","# process_structure[\"bg\"][\"train_loader\"] = bg_unbiased_train_dataloader\n","# process_structure[\"bg\"][\"test_loader\"] = bg_unbiased_test_dataloader\n","# process_structure[\"bg\"][\"saveas\"] = save_bg_unbiased_colour_mnist_model_as\n","# process_structure[\"bg\"][\"loadfrom\"] = bg_unbiased_colour_mnist_model_to_load\n","\n","# \"biased_colour_mnist\"\n","# process_structure[\"bias\"][\"model\"] = torchvision.models.resnet18(num_classes=10).to(device) # Untrained model\n","# process_structure[\"bias\"][\"train\"] = train_biased_colour_mnist_model\n","# process_structure[\"bias\"][\"train_loader\"] = biased_train_dataloader\n","# process_structure[\"bias\"][\"test_loader\"] = biased_test_dataloader\n","# process_structure[\"bias\"][\"saveas\"] = save_biased_colour_mnist_model_as\n","# process_structure[\"bias\"][\"loadfrom\"] =  biased_colour_mnist_model_to_load\n","#\n","# # \"unbiased_colour_mnist\"\n","# process_structure[\"unbias\"][\"model\"] = torchvision.models.resnet18(num_classes=10).to(device) # Untrained model\n","# process_structure[\"unbias\"][\"train\"] = train_unbiased_colour_mnist_model\n","# process_structure[\"unbias\"][\"train_loader\"] = unbiased_train_dataloader\n","# process_structure[\"unbias\"][\"test_loader\"] = unbiased_test_dataloader\n","# process_structure[\"unbias\"][\"saveas\"] = save_unbiased_colour_mnist_model_as\n","# process_structure[\"unbias\"][\"loadfrom\"] =  unbiased_colour_mnist_model_to_load\n","\n","for key, val in process_structure.items():\n","    print(f\"Processing for {key=}\")\n","    if key == \"randinit\":\n","        if gen_randinit_model:  # create new model but don't train it\n","            logtofile(f\"model has already been initialised: save it as {val['saveas']}\")\n","            torch.save(val[\"model\"].state_dict(), val[\"saveas\"])\n","        else:\n","            logtofile(f\"{val['loadfrom']=}\")\n","            val[\"model\"].load_state_dict(torch.load(val[\"loadfrom\"], map_location=torch.device(device)))\n","    else:\n","        if val[\"train\"]:\n","            train_model(model=val[\"model\"], train_loader=val[\"train_loader\"],\n","                        epochs=original_train_epochs, saveas=val[\"saveas\"],\n","                        description=key, device=device, logtofile=logtofile)\n","        else:\n","            logtofile(f\"{val['loadfrom']=}\")\n","            val[\"model\"].load_state_dict(torch.load(val[\"loadfrom\"], map_location=torch.device(device)))\n","    val[\"model\"].eval()\n"]},{"cell_type":"markdown","id":"b169c5c7-7929-48e1-82eb-6f047aa4e5f2","metadata":{"id":"b169c5c7-7929-48e1-82eb-6f047aa4e5f2"},"source":["## Measure the Accuracy, Record the Confusion Matrix\n"]},{"cell_type":"code","execution_count":15,"id":"4fbb925a-269d-4027-9500-6cdce4de9d70","metadata":{"id":"4fbb925a-269d-4027-9500-6cdce4de9d70","outputId":"d2c034eb-2b7f-463e-ac5d-dca3cf275f9a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747512007489,"user_tz":-60,"elapsed":14711,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Entering Confusion\n","Accuracy Calculation for ResNet18 with key='bw'\n","Test the Trained Resnet18 against OWN TEST LOADER: key='bw'\n","Test Accuracy: 99.09 %\n","Confusion Matrix\n","tensor([[ 979,    0,    0,    0,    0,    1,    0,    0,    0,    0],\n","        [   0, 1132,    0,    0,    0,    2,    1,    0,    0,    0],\n","        [   1,    1, 1025,    3,    1,    0,    0,    1,    0,    0],\n","        [   1,    0,    0, 1000,    0,    5,    0,    0,    3,    1],\n","        [   0,    0,    0,    0,  973,    0,    0,    1,    0,    8],\n","        [   2,    0,    0,    1,    0,  881,    1,    0,    2,    5],\n","        [   3,    4,    0,    0,    0,    2,  948,    0,    1,    0],\n","        [   0,    5,    9,    2,    0,    0,    0, 1006,    1,    5],\n","        [   3,    0,    1,    0,    0,    1,    0,    2,  965,    2],\n","        [   1,    1,    0,    2,    3,    1,    0,    0,    1, 1000]],\n","       dtype=torch.int32)\n","tensor(10000)\n","Accuracy Calculation for ResNet18 with key='bgonly'\n","Test the Trained Resnet18 against OWN TEST LOADER: key='bgonly'\n","Test Accuracy: 100.00 %\n","Confusion Matrix\n","tensor([[ 980,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   0, 1135,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [   0,    0, 1032,    0,    0,    0,    0,    0,    0,    0],\n","        [   0,    0,    0, 1010,    0,    0,    0,    0,    0,    0],\n","        [   0,    0,    0,    0,  982,    0,    0,    0,    0,    0],\n","        [   0,    0,    0,    0,    0,  892,    0,    0,    0,    0],\n","        [   0,    0,    0,    0,    0,    0,  958,    0,    0,    0],\n","        [   0,    0,    0,    0,    0,    0,    0, 1028,    0,    0],\n","        [   0,    0,    0,    0,    0,    0,    0,    0,  974,    0],\n","        [   0,    0,    0,    0,    0,    0,    0,    0,    0, 1009]],\n","       dtype=torch.int32)\n","tensor(10000)\n","Accuracy Calculation for ResNet18 with key='randinit'\n","Test the Trained Resnet18 against OWN TEST LOADER: key='randinit'\n","Test Accuracy: 10.10 %\n","Confusion Matrix\n","tensor([[   0,    1,    0,  977,    0,    0,    2,    0,    0,    0],\n","        [   0,    0,    0, 1123,    0,    0,   12,    0,    0,    0],\n","        [   0,    1,    0, 1025,    0,    0,    6,    0,    0,    0],\n","        [   0,    0,    0, 1010,    0,    0,    0,    0,    0,    0],\n","        [   0,    0,    0,  982,    0,    0,    0,    0,    0,    0],\n","        [   0,    0,    0,  892,    0,    0,    0,    0,    0,    0],\n","        [   0,    0,    0,  958,    0,    0,    0,    0,    0,    0],\n","        [   0,    0,    0, 1028,    0,    0,    0,    0,    0,    0],\n","        [   0,    0,    0,  974,    0,    0,    0,    0,    0,    0],\n","        [   0,    0,    0, 1009,    0,    0,    0,    0,    0,    0]],\n","       dtype=torch.int32)\n","tensor(10000)\n","original_accuracy={'bw': 99.09, 'bgonly': 100.0, 'randinit': 10.1}\n"]}],"source":["logtofile(\"Entering Confusion\")\n","# logtofile(process.memory_info().rss)  # in bytes\n","\n","original_accuracy = dict()\n","for key, val in process_structure.items():\n","    logtofile(f\"Accuracy Calculation for ResNet18 with {key=}\")\n","    model = val[\"model\"]\n","    model.eval() # ALWAYS DO THIS BEFORE YOU EVALUATE MODELS\n","\n","    # Compute the model accuracy on the test set\n","    correct = 0\n","    total = 0\n","\n","    # assuming 10 classes\n","    # rows represent actual class, columns are predicted\n","    confusion_matrix = torch.zeros(10,10, dtype=torch.int)\n","\n","    TDL = val[\"test_loader\"] # use the test loader for the dataset the model was trained on\n","    for data in TDL:\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        predictions = torch.argmax(model(inputs),1)\n","\n","        matches = predictions == labels\n","        correct += matches.sum().item()\n","        total += len(labels)\n","        for idx, l in enumerate(labels):\n","            confusion_matrix[l, predictions[idx]] = 1 + confusion_matrix[l, predictions[idx]]\n","\n","    logtofile(f\"Test the Trained Resnet18 against OWN TEST LOADER: {key=}\")\n","    acc = ((100.0 * correct) / total)\n","    logtofile('Test Accuracy: %2.2f %%' % acc)\n","    original_accuracy[key] = acc\n","    logtofile('Confusion Matrix')\n","    logtofile(confusion_matrix)\n","    logtofile(confusion_matrix.sum())\n","    # logtofile(process.memory_info().rss)  # in bytes\n","\n","\n","logtofile(f\"{original_accuracy=}\")"]},{"cell_type":"markdown","id":"da373b34-fe35-4256-a9e0-1040f699d45d","metadata":{"id":"da373b34-fe35-4256-a9e0-1040f699d45d"},"source":["## Measure Rank with __OWN__ dataloader (test) before cutting and stitching"]},{"cell_type":"code","execution_count":16,"id":"c4f74591-2a3f-4521-8aec-32c324125a5b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4f74591-2a3f-4521-8aec-32c324125a5b","outputId":"6533089d-fcf6-43a2-9bf7-c89fc089ac83","executionInfo":{"status":"ok","timestamp":1747512007521,"user_tz":-60,"elapsed":77,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Entering whole model check\n"]}],"source":["logtofile(\"Entering whole model check\")\n","# logtofile(process.memory_info().rss)  # in bytes\n","if measure_rank:\n","  # For the Whole Model - but we will pass it through the RcvResNet18 function to get matching feature names\n","  for key, val in process_structure.items():\n","\n","      #TDL = biased_test_dataloader  # ALWAYS use biased dataloader for this test\n","      TDL = val[\"test_loader\"] # use the test loader for the dataset the model was trained on\n","      if val[\"train\"]:\n","          filename = val[\"saveas\"]\n","      else:\n","          filename = val[\"loadfrom\"]\n","      assert os.path.exists(filename)\n","      mdl = torchvision.models.resnet18(num_classes=10) # Untrained model\n","      state = torch.load(filename, map_location=torch.device(\"cpu\"))\n","      mdl.load_state_dict(state, assign=True)\n","      mdl=mdl.to(device)\n","      mdl = RcvResNet18(mdl, -1, colour_mnist_shape, device).to(device)\n","\n","      out_filename = filename.split('/')[-1].replace('.weights', '-test.csv')\n","\n","      outpath = f\"./{results_root}_rank/{key}-bias-{seed}_{out_filename}\"  # denote output name as <model_training_type>-dataset-<name>\n","\n","      if os.path.exists(f\"{outpath}\"):\n","          logtofile(f\"Already evaluated for {outpath}\")\n","          continue\n","      logtofile(f\"Measure Rank for {key=}\")\n","      print(f\"output to {outpath}\")\n","\n","      params = {}\n","      params[\"model\"] = key\n","      params[\"dataset\"] = key\n","      params[\"seed\"] = seed\n","      if val[\"train\"]: # as only one network used, record its filename as both send and receive files\n","          params[\"send_file\"] = val[\"saveas\"]\n","          params[\"rcv_file\"] = val[\"saveas\"]\n","      else:\n","          params[\"send_file\"] = val[\"loadfrom\"]\n","          params[\"rcv_file\"] = val[\"loadfrom\"]\n","\n","      with torch.no_grad():\n","          layers, features, handles = install_hooks(mdl)\n","\n","          metrics = evaluate_model(mdl, TDL, 'acc', verbose=2)\n","          params.update(metrics)\n","\n","          classes = None\n","          df = perform_analysis(features, classes, layers, params, n=-1)\n","          df.to_csv(f\"{outpath}\")\n","      for h in handles:\n","          h.remove()\n","      del mdl, layers, features, metrics, params, df, handles\n","      gc.collect()\n","      # logtofile(process.memory_info().rss)  # in bytes\n","\n"]},{"cell_type":"markdown","id":"de2928d3-9c5f-411f-a590-14fd04026ab6","metadata":{"id":"de2928d3-9c5f-411f-a590-14fd04026ab6"},"source":["# Stitch at a given layer\n"]},{"cell_type":"markdown","id":"3cbaf773-ed43-4d91-b0a0-a35fd468ac02","metadata":{"id":"3cbaf773-ed43-4d91-b0a0-a35fd468ac02"},"source":["## Train the stitch layer and check rank"]},{"cell_type":"code","execution_count":17,"id":"2c29d808-b86e-4a0c-a3c5-127c952f3ab9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2c29d808-b86e-4a0c-a3c5-127c952f3ab9","outputId":"ff865c3e-3d1b-4fbf-f307-528103c286d8","executionInfo":{"status":"ok","timestamp":1747516891639,"user_tz":-60,"elapsed":84616,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Entering Stitch/Rank\n","device='cuda'\n","NOTE: Only running stitch to bgonly: skipping\n","stitching bw to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bw3bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 3 from bw to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 3 of send_model is: torch.Size([1, 64, 7, 7])\n","Epoch 0, loss 2521.52\n","Epoch 1, loss 916.95\n","Epoch 2, loss 640.62\n","Epoch 3, loss 534.98\n","Epoch 4, loss 488.35\n","Epoch 5, loss 453.78\n","Epoch 6, loss 426.97\n","Epoch 7, loss 403.46\n","Epoch 8, loss 383.03\n","Epoch 9, loss 375.87\n","**** Finished Training ****\n","Change in stitch weights: 2.5872228145599365\n","Largest abs weight change: 0.16481700539588928\n","Number of weights changing > 0.1 of that: 2763\n","Number of weight / bias in stitch layer is 64\n","Change in stitch bias: 0.026458751410245895\n","Largest abs bias change: 0.005700156092643738\n","Number of bias changing > 0.1 of that: 62\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 85.10 %\n","Confusion Matrix\n","tensor([[ 909,    0,    4,    0,   16,    0,   30,   20,    1,    0],\n","        [   0, 1073,    2,    5,   19,    1,   30,    1,    3,    1],\n","        [   5,    0,  855,   29,    7,    0,   63,   65,    8,    0],\n","        [   0,    0,   16,  951,    2,    1,    7,   15,   16,    2],\n","        [  20,    3,    3,    2,  836,    0,   33,   47,   33,    5],\n","        [   1,    1,    7,   64,   79,  662,    6,    6,   55,   11],\n","        [  19,    2,   17,    0,   17,    1,  869,    2,   31,    0],\n","        [  17,    3,   42,   12,   17,    0,    8,  909,    9,   11],\n","        [   2,    1,   47,   46,   54,    3,   91,   13,  712,    5],\n","        [   5,    4,    7,    6,   41,    0,   26,  101,   85,  734]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bw3bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bw to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bw4bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 4 from bw to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 4 of send_model is: torch.Size([1, 64, 7, 7])\n","Epoch 0, loss 2340.23\n","Epoch 1, loss 436.41\n","Epoch 2, loss 310.65\n","Epoch 3, loss 260.80\n","Epoch 4, loss 217.69\n","Epoch 5, loss 195.23\n","Epoch 6, loss 179.49\n","Epoch 7, loss 161.31\n","Epoch 8, loss 148.42\n","Epoch 9, loss 143.11\n","**** Finished Training ****\n","Change in stitch weights: 2.1366612911224365\n","Largest abs weight change: 0.15155358612537384\n","Number of weights changing > 0.1 of that: 2630\n","Number of weight / bias in stitch layer is 64\n","Change in stitch bias: 0.025746697559952736\n","Largest abs bias change: 0.005546979606151581\n","Number of bias changing > 0.1 of that: 58\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 94.10 %\n","Confusion Matrix\n","tensor([[ 926,    0,    0,    0,   20,    0,   12,   21,    1,    0],\n","        [   0, 1114,    2,    4,    7,    0,    4,    2,    1,    1],\n","        [   1,    0,  976,    9,    2,    0,    5,   31,    8,    0],\n","        [   0,    0,    6,  984,    4,    4,    0,    2,   10,    0],\n","        [  11,    5,    0,    0,  917,    0,    9,   21,   13,    6],\n","        [   0,    2,    2,   16,   34,  805,    5,    3,   20,    5],\n","        [  12,    6,    1,    0,   12,    3,  919,    0,    5,    0],\n","        [   0,    0,   14,    7,    9,    0,    0,  977,    5,   16],\n","        [   0,    1,   10,   27,   10,    0,   23,   11,  886,    6],\n","        [   1,    1,    2,    2,   20,    4,    0,   35,   38,  906]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bw4bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bw to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bw5bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 5 from bw to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 5 of send_model is: torch.Size([1, 128, 4, 4])\n","Epoch 0, loss 381.00\n","Epoch 1, loss 82.91\n","Epoch 2, loss 63.16\n","Epoch 3, loss 52.93\n","Epoch 4, loss 48.71\n","Epoch 5, loss 44.60\n","Epoch 6, loss 39.83\n","Epoch 7, loss 38.64\n","Epoch 8, loss 35.89\n","Epoch 9, loss 33.68\n","**** Finished Training ****\n","Change in stitch weights: 1.3765692710876465\n","Largest abs weight change: 0.05355389416217804\n","Number of weights changing > 0.1 of that: 9694\n","Number of weight / bias in stitch layer is 128\n","Change in stitch bias: 0.026576964184641838\n","Largest abs bias change: 0.003994613885879517\n","Number of bias changing > 0.1 of that: 116\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 98.35 %\n","Confusion Matrix\n","tensor([[ 968,    0,    0,    0,    5,    0,    6,    1,    0,    0],\n","        [   0, 1122,    1,    2,    3,    1,    4,    0,    2,    0],\n","        [   0,    1, 1015,    1,    1,    0,    5,    8,    1,    0],\n","        [   0,    0,    2,  994,    1,    4,    1,    1,    6,    1],\n","        [   1,    1,    1,    0,  966,    0,    1,    3,    4,    5],\n","        [   1,    0,    0,    8,    3,  873,    2,    0,    2,    3],\n","        [   3,    1,    0,    0,    2,    3,  948,    0,    1,    0],\n","        [   0,    0,    5,    1,    8,    0,    0, 1011,    0,    3],\n","        [   0,    0,    2,    0,    4,    0,    3,    2,  960,    3],\n","        [   0,    1,    0,    2,    5,    4,    2,    7,   10,  978]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bw5bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bw to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bw6bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 6 from bw to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 6 of send_model is: torch.Size([1, 256, 2, 2])\n","Epoch 0, loss 146.84\n","Epoch 1, loss 27.51\n","Epoch 2, loss 22.24\n","Epoch 3, loss 20.42\n","Epoch 4, loss 17.94\n","Epoch 5, loss 16.49\n","Epoch 6, loss 16.49\n","Epoch 7, loss 15.11\n","Epoch 8, loss 14.62\n","Epoch 9, loss 13.84\n","**** Finished Training ****\n","Change in stitch weights: 0.8844122290611267\n","Largest abs weight change: 0.04022865742444992\n","Number of weights changing > 0.1 of that: 13116\n","Number of weight / bias in stitch layer is 256\n","Change in stitch bias: 0.02686396986246109\n","Largest abs bias change: 0.0028512924909591675\n","Number of bias changing > 0.1 of that: 227\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 98.94 %\n","Confusion Matrix\n","tensor([[ 975,    0,    0,    1,    0,    1,    0,    0,    1,    2],\n","        [   0, 1124,    2,    3,    2,    1,    1,    1,    1,    0],\n","        [   0,    1, 1021,    2,    1,    0,    1,    5,    1,    0],\n","        [   1,    0,    0, 1005,    0,    2,    0,    0,    2,    0],\n","        [   0,    0,    3,    0,  971,    0,    0,    3,    1,    4],\n","        [   1,    0,    0,    7,    1,  880,    1,    0,    0,    2],\n","        [   2,    2,    0,    0,    2,    4,  946,    0,    2,    0],\n","        [   0,    1,    3,    3,    4,    0,    0, 1013,    0,    4],\n","        [   2,    0,    3,    1,    0,    1,    0,    2,  964,    1],\n","        [   1,    0,    0,    2,    4,    3,    0,    1,    3,  995]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bw6bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bw to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bw7bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 7 from bw to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 7 of send_model is: torch.Size([1, 512, 1, 1])\n","Epoch 0, loss 66.75\n","Epoch 1, loss 15.27\n","Epoch 2, loss 12.91\n","Epoch 3, loss 11.74\n","Epoch 4, loss 10.93\n","Epoch 5, loss 10.62\n","Epoch 6, loss 10.56\n","Epoch 7, loss 9.75\n","Epoch 8, loss 9.61\n","Epoch 9, loss 9.69\n","**** Finished Training ****\n","Change in stitch weights: 0.8724979758262634\n","Largest abs weight change: 0.016722651198506355\n","Number of weights changing > 0.1 of that: 79401\n","Number of weight / bias in stitch layer is 512\n","Change in stitch bias: 0.026311570778489113\n","Largest abs bias change: 0.002013571560382843\n","Number of bias changing > 0.1 of that: 468\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 99.20 %\n","Confusion Matrix\n","tensor([[ 978,    0,    1,    0,    0,    0,    0,    1,    0,    0],\n","        [   0, 1128,    1,    2,    0,    1,    1,    2,    0,    0],\n","        [   0,    0, 1025,    2,    1,    0,    0,    4,    0,    0],\n","        [   0,    0,    0, 1005,    0,    3,    1,    0,    0,    1],\n","        [   0,    0,    1,    0,  975,    0,    0,    1,    0,    5],\n","        [   2,    0,    0,    6,    0,  878,    1,    0,    1,    4],\n","        [   2,    4,    0,    0,    2,    1,  948,    0,    1,    0],\n","        [   0,    2,    4,    0,    0,    0,    0, 1019,    1,    2],\n","        [   1,    0,    1,    0,    0,    1,    0,    2,  967,    2],\n","        [   0,    0,    0,    2,    4,    1,    0,    4,    1,  997]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bw7bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bw to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bw8bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 8 from bw to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 8 of send_model is: torch.Size([1, 512, 1, 1])\n","Epoch 0, loss 61.02\n","Epoch 1, loss 14.70\n","Epoch 2, loss 12.41\n","Epoch 3, loss 11.91\n","Epoch 4, loss 11.15\n","Epoch 5, loss 10.67\n","Epoch 6, loss 10.41\n","Epoch 7, loss 9.79\n","Epoch 8, loss 9.83\n","Epoch 9, loss 9.63\n","**** Finished Training ****\n","Change in stitch weights: 0.8484953045845032\n","Largest abs weight change: 0.01586695946753025\n","Number of weights changing > 0.1 of that: 85226\n","Number of weight / bias in stitch layer is 512\n","Change in stitch bias: 0.026004215702414513\n","Largest abs bias change: 0.002012450248003006\n","Number of bias changing > 0.1 of that: 463\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 99.19 %\n","Confusion Matrix\n","tensor([[ 978,    0,    1,    0,    0,    0,    0,    1,    0,    0],\n","        [   0, 1128,    1,    2,    0,    1,    1,    2,    0,    0],\n","        [   1,    0, 1026,    1,    1,    0,    0,    3,    0,    0],\n","        [   1,    0,    1, 1001,    0,    4,    0,    0,    1,    2],\n","        [   0,    0,    1,    0,  976,    0,    0,    0,    0,    5],\n","        [   2,    0,    0,    5,    0,  879,    1,    0,    1,    4],\n","        [   2,    3,    0,    0,    1,    1,  949,    0,    2,    0],\n","        [   0,    2,    2,    0,    0,    0,    0, 1021,    1,    2],\n","        [   3,    0,    1,    1,    0,    1,    0,    2,  964,    2],\n","        [   1,    0,    0,    2,    4,    1,    0,    3,    1,  997]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bw8bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","NOTE: Only running stitch to bgonly: skipping\n","NOTE: Only running stitch to bgonly: skipping\n","stitching bgonly to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bgonly3bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 3 from bgonly to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 3 of send_model is: torch.Size([1, 64, 7, 7])\n","Epoch 0, loss 2951.56\n","Epoch 1, loss 1489.20\n","Epoch 2, loss 1110.30\n","Epoch 3, loss 925.95\n","Epoch 4, loss 814.37\n","Epoch 5, loss 758.99\n","Epoch 6, loss 696.08\n","Epoch 7, loss 661.51\n","Epoch 8, loss 655.81\n","Epoch 9, loss 616.96\n","**** Finished Training ****\n","Change in stitch weights: 2.6421260833740234\n","Largest abs weight change: 0.30812886357307434\n","Number of weights changing > 0.1 of that: 1426\n","Number of weight / bias in stitch layer is 64\n","Change in stitch bias: 0.028009897097945213\n","Largest abs bias change: 0.0056239888072013855\n","Number of bias changing > 0.1 of that: 59\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 70.23 %\n","Confusion Matrix\n","tensor([[ 905,    0,    1,    0,   44,    0,   16,   13,    0,    1],\n","        [   1, 1022,    1,    1,   75,    0,   12,    2,   21,    0],\n","        [  45,    0,  746,   15,   31,    0,   90,   69,   33,    3],\n","        [  14,    0,   22,  835,   36,    1,   45,   15,   40,    2],\n","        [  48,   24,    2,    5,  725,    0,   39,   74,   61,    4],\n","        [   6,    4,    9,   36,  133,  638,    7,    5,   44,   10],\n","        [  83,   16,    0,    7,   68,    2,  754,    3,   25,    0],\n","        [  57,    1,   25,   11,  177,    1,    7,  694,   45,   10],\n","        [  50,   10,   16,   41,  181,    4,  233,   58,  325,   56],\n","        [  24,   19,    0,   13,  211,    4,   13,  167,  179,  379]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bgonly3bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bgonly to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bgonly4bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 4 from bgonly to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 4 of send_model is: torch.Size([1, 64, 7, 7])\n","Epoch 0, loss 2526.51\n","Epoch 1, loss 1653.60\n","Epoch 2, loss 1235.26\n","Epoch 3, loss 757.87\n","Epoch 4, loss 584.72\n","Epoch 5, loss 518.42\n","Epoch 6, loss 474.39\n","Epoch 7, loss 425.78\n","Epoch 8, loss 406.61\n","Epoch 9, loss 381.91\n","**** Finished Training ****\n","Change in stitch weights: 2.606123685836792\n","Largest abs weight change: 0.19549992680549622\n","Number of weights changing > 0.1 of that: 2383\n","Number of weight / bias in stitch layer is 64\n","Change in stitch bias: 0.02738422155380249\n","Largest abs bias change: 0.005569949746131897\n","Number of bias changing > 0.1 of that: 57\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 83.27 %\n","Confusion Matrix\n","tensor([[ 788,    1,   32,    0,   79,    2,   20,   55,    3,    0],\n","        [   0, 1097,    2,    4,    8,    0,    7,    0,   17,    0],\n","        [   7,    0,  910,    7,   10,    0,   46,   47,    4,    1],\n","        [   7,    0,   41,  836,   10,    7,    5,   25,   68,   11],\n","        [   7,   22,    3,    0,  830,    0,   28,   57,   25,   10],\n","        [   7,   11,   12,   54,   97,  645,   12,    7,   35,   12],\n","        [  16,    8,   45,    0,   29,    4,  827,    4,   25,    0],\n","        [  11,    5,   36,    2,   39,    0,    4,  879,   10,   42],\n","        [   2,   10,   48,   31,   58,    8,   50,   14,  737,   16],\n","        [   1,   16,    3,    8,   54,    5,   10,   86,   48,  778]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bgonly4bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bgonly to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bgonly5bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 5 from bgonly to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 5 of send_model is: torch.Size([1, 128, 4, 4])\n","Epoch 0, loss 1834.43\n","Epoch 1, loss 1046.93\n","Epoch 2, loss 764.98\n","Epoch 3, loss 595.83\n","Epoch 4, loss 489.55\n","Epoch 5, loss 397.23\n","Epoch 6, loss 347.01\n","Epoch 7, loss 310.23\n","Epoch 8, loss 284.93\n","Epoch 9, loss 268.01\n","**** Finished Training ****\n","Change in stitch weights: 2.506460189819336\n","Largest abs weight change: 0.1153818666934967\n","Number of weights changing > 0.1 of that: 8583\n","Number of weight / bias in stitch layer is 128\n","Change in stitch bias: 0.02552795223891735\n","Largest abs bias change: 0.004026725888252258\n","Number of bias changing > 0.1 of that: 115\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 88.53 %\n","Confusion Matrix\n","tensor([[ 905,    1,    5,    2,   16,    3,   27,   10,    8,    3],\n","        [   0, 1088,    7,    5,   10,    0,   17,    1,    5,    2],\n","        [   5,    1,  925,   23,    3,    3,   31,   28,   12,    1],\n","        [   5,    4,   25,  905,    1,   21,    2,   15,   25,    7],\n","        [   0,    8,    1,    0,  881,    2,   29,   16,   15,   30],\n","        [   9,    5,   10,   52,   32,  720,   16,    3,   28,   17],\n","        [  10,    6,    9,    2,   21,    9,  894,    0,    7,    0],\n","        [   2,   11,   27,   13,   11,    4,    0,  915,   12,   33],\n","        [   7,    3,   32,   15,   36,   14,   29,    5,  809,   24],\n","        [   4,    7,    0,   10,   51,   10,    3,   69,   44,  811]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bgonly5bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bgonly to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bgonly6bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 6 from bgonly to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 6 of send_model is: torch.Size([1, 256, 2, 2])\n","Epoch 0, loss 1197.48\n","Epoch 1, loss 634.68\n","Epoch 2, loss 499.84\n","Epoch 3, loss 426.16\n","Epoch 4, loss 377.31\n","Epoch 5, loss 344.18\n","Epoch 6, loss 315.88\n","Epoch 7, loss 291.27\n","Epoch 8, loss 278.39\n","Epoch 9, loss 268.77\n","**** Finished Training ****\n","Change in stitch weights: 2.119163751602173\n","Largest abs weight change: 0.08339549601078033\n","Number of weights changing > 0.1 of that: 17733\n","Number of weight / bias in stitch layer is 256\n","Change in stitch bias: 0.026827096939086914\n","Largest abs bias change: 0.0028412044048309326\n","Number of bias changing > 0.1 of that: 235\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 83.75 %\n","Confusion Matrix\n","tensor([[ 922,    0,    4,    2,    9,   13,   14,    4,    9,    3],\n","        [   0, 1101,    3,    2,   14,    1,    4,    1,    6,    3],\n","        [  24,    5,  662,  156,    7,   32,   85,   23,   25,   13],\n","        [   7,    7,    8,  879,    1,   19,    1,   26,   38,   24],\n","        [   3,    8,    2,    0,  871,    7,   18,    6,    9,   58],\n","        [  26,   13,   11,   59,   17,  664,   28,   13,   34,   27],\n","        [  29,   18,    3,    3,   40,   21,  829,    2,   12,    1],\n","        [  12,   24,   20,   20,   21,    9,    2,  860,   10,   50],\n","        [  36,    5,    4,   31,   36,   24,   15,   11,  773,   39],\n","        [  13,    8,    0,   14,   74,    7,    2,   57,   20,  814]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bgonly6bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bgonly to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bgonly7bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 7 from bgonly to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 7 of send_model is: torch.Size([1, 512, 1, 1])\n","Epoch 0, loss 954.69\n","Epoch 1, loss 857.18\n","Epoch 2, loss 822.51\n","Epoch 3, loss 793.59\n","Epoch 4, loss 771.17\n","Epoch 5, loss 749.15\n","Epoch 6, loss 736.60\n","Epoch 7, loss 718.69\n","Epoch 8, loss 706.04\n","Epoch 9, loss 694.97\n","**** Finished Training ****\n","Change in stitch weights: 1.509878158569336\n","Largest abs weight change: 0.06255173683166504\n","Number of weights changing > 0.1 of that: 10484\n","Number of weight / bias in stitch layer is 512\n","Change in stitch bias: 0.02619510516524315\n","Largest abs bias change: 0.002013258635997772\n","Number of bias changing > 0.1 of that: 455\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 53.38 %\n","Confusion Matrix\n","tensor([[695,  12,  50,  43,  15,  52,  16,  31,  61,   5],\n","        [  0, 977,   3,   4,  28,   4,  17,  33,  15,  54],\n","        [118,  49, 462,  99,  21,  67,  59,  56,  94,   7],\n","        [ 66,  58,  90, 459,   4,  55,  11, 128, 115,  24],\n","        [ 15,  86,  12,   3, 491,  21,  60, 171,  21, 102],\n","        [ 75,  78,  59, 123,  17, 340,  18,  87,  58,  37],\n","        [ 70,  67,  81,  25,  81,  36, 442,  73,  61,  22],\n","        [ 10, 100,  36,  25,  40,  20,   9, 686,  32,  70],\n","        [115,  26,  78,  92,  11,  37,  42,  79, 431,  63],\n","        [ 32,  34,  10,  11, 134,  22,  20, 346,  45, 355]], dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bgonly7bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching bgonly to bgonly\n","Evaluate ranks and output to ./results_2n_rank/bgonly8bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 8 from bgonly to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 8 of send_model is: torch.Size([1, 512, 1, 1])\n","Epoch 0, loss 950.51\n","Epoch 1, loss 862.63\n","Epoch 2, loss 827.27\n","Epoch 3, loss 799.24\n","Epoch 4, loss 774.14\n","Epoch 5, loss 753.47\n","Epoch 6, loss 736.32\n","Epoch 7, loss 721.29\n","Epoch 8, loss 707.78\n","Epoch 9, loss 696.49\n","**** Finished Training ****\n","Change in stitch weights: 1.506712794303894\n","Largest abs weight change: 0.0524626225233078\n","Number of weights changing > 0.1 of that: 14807\n","Number of weight / bias in stitch layer is 512\n","Change in stitch bias: 0.02642870880663395\n","Largest abs bias change: 0.002014748752117157\n","Number of bias changing > 0.1 of that: 460\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 54.98 %\n","Confusion Matrix\n","tensor([[646,  11,  95,  35,   5,  60,  20,  19,  71,  18],\n","        [  4, 978,   2,   5,  34,   3,  10,  14,  10,  75],\n","        [ 59,  53, 493,  87,  29,  60,  83,  60,  94,  14],\n","        [ 28,  64, 122, 438,   6,  70,  11, 105, 130,  36],\n","        [ 30,  93,   7,   7, 556,   9,  64,  58,  28, 130],\n","        [ 42,  97,  78,  96,  25, 345,  31,  63,  69,  46],\n","        [ 39,  60,  85,  29,  88,  33, 483,  32,  85,  24],\n","        [  8, 122,  29,  35,  72,  17,  12, 572,  15, 146],\n","        [ 51,  32, 125,  66,  13,  28,  41,  43, 457, 118],\n","        [ 22,  65,  18,  12, 150,  16,  17, 152,  27, 530]], dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/bgonly8bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","NOTE: Only running stitch to bgonly: skipping\n","NOTE: Only running stitch to bgonly: skipping\n","stitching randinit to bgonly\n","Evaluate ranks and output to ./results_2n_rank/randinit3bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 3 from randinit to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 3 of send_model is: torch.Size([1, 64, 7, 7])\n","Epoch 0, loss 3924.77\n","Epoch 1, loss 1588.01\n","Epoch 2, loss 1060.90\n","Epoch 3, loss 873.19\n","Epoch 4, loss 769.23\n","Epoch 5, loss 687.49\n","Epoch 6, loss 623.70\n","Epoch 7, loss 590.59\n","Epoch 8, loss 547.16\n","Epoch 9, loss 529.56\n","**** Finished Training ****\n","Change in stitch weights: 2.926251173019409\n","Largest abs weight change: 0.1859511435031891\n","Number of weights changing > 0.1 of that: 2780\n","Number of weight / bias in stitch layer is 64\n","Change in stitch bias: 0.027575375512242317\n","Largest abs bias change: 0.005651131272315979\n","Number of bias changing > 0.1 of that: 62\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 79.54 %\n","Confusion Matrix\n","tensor([[843,   0,   7,   2,  48,   0,  32,  47,   1,   0],\n","        [  1, 956,   2,   4, 139,   0,  27,   2,   4,   0],\n","        [  1,   0, 866,  22,  18,   4,  43,  60,  14,   4],\n","        [  2,   1,  41, 850,  12,  11,  13,  15,  63,   2],\n","        [ 16,   5,  10,   2, 875,   0,   8,  42,  15,   9],\n","        [  1,   9,   9,  33,  55, 719,  14,   3,  39,  10],\n","        [  9,   8,  19,  16,  35,   9, 814,   5,  41,   2],\n","        [  3,   4,  39,  12,  68,   1,  14, 834,  24,  29],\n","        [  3,  13,  53,  38, 108,  25,  55,  29, 609,  41],\n","        [  6,   8,  16,  12,  96,  11,  17, 149, 106, 588]], dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/randinit3bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching randinit to bgonly\n","Evaluate ranks and output to ./results_2n_rank/randinit4bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 4 from randinit to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 4 of send_model is: torch.Size([1, 64, 7, 7])\n","Epoch 0, loss 2655.22\n","Epoch 1, loss 1040.07\n","Epoch 2, loss 732.60\n","Epoch 3, loss 601.05\n","Epoch 4, loss 529.69\n","Epoch 5, loss 478.69\n","Epoch 6, loss 436.65\n","Epoch 7, loss 408.68\n","Epoch 8, loss 384.03\n","Epoch 9, loss 361.57\n","**** Finished Training ****\n","Change in stitch weights: 2.863276481628418\n","Largest abs weight change: 0.16589081287384033\n","Number of weights changing > 0.1 of that: 2874\n","Number of weight / bias in stitch layer is 64\n","Change in stitch bias: 0.024272553622722626\n","Largest abs bias change: 0.005566291511058807\n","Number of bias changing > 0.1 of that: 57\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 85.02 %\n","Confusion Matrix\n","tensor([[ 879,    1,    3,    1,   41,    0,   30,   25,    0,    0],\n","        [   0, 1092,    1,    4,    6,    0,   23,    2,    7,    0],\n","        [   8,    0,  905,   23,    8,    0,   31,   39,   16,    2],\n","        [   9,    1,   29,  875,   17,    9,   11,   12,   44,    3],\n","        [   5,   37,    0,    2,  818,    1,   23,   68,   15,   13],\n","        [   4,    4,    7,   23,   62,  736,   10,    2,   33,   11],\n","        [  18,   20,    8,    2,   33,    4,  859,    4,   10,    0],\n","        [  12,    7,   40,    4,   36,    0,    0,  898,   11,   20],\n","        [   4,    5,   43,   66,   61,    7,   50,   23,  685,   30],\n","        [   2,    7,    3,   12,   77,    6,    5,   90,   52,  755]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/randinit4bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching randinit to bgonly\n","Evaluate ranks and output to ./results_2n_rank/randinit5bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 5 from randinit to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 5 of send_model is: torch.Size([1, 128, 4, 4])\n","Epoch 0, loss 2062.42\n","Epoch 1, loss 647.23\n","Epoch 2, loss 467.40\n","Epoch 3, loss 382.45\n","Epoch 4, loss 336.34\n","Epoch 5, loss 301.01\n","Epoch 6, loss 275.95\n","Epoch 7, loss 253.88\n","Epoch 8, loss 239.26\n","Epoch 9, loss 226.97\n","**** Finished Training ****\n","Change in stitch weights: 2.880575656890869\n","Largest abs weight change: 0.10129345953464508\n","Number of weights changing > 0.1 of that: 10534\n","Number of weight / bias in stitch layer is 128\n","Change in stitch bias: 0.026415875181555748\n","Largest abs bias change: 0.004003264009952545\n","Number of bias changing > 0.1 of that: 112\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 89.66 %\n","Confusion Matrix\n","tensor([[ 897,    1,    5,    1,   21,    1,   39,   10,    4,    1],\n","        [   0, 1115,    1,    2,    4,    0,    7,    2,    4,    0],\n","        [   0,    0,  904,   17,   18,    1,   17,   35,   39,    1],\n","        [   1,    3,   15,  902,   18,   15,    9,    9,   36,    2],\n","        [   3,   10,    2,    1,  908,    2,   15,   20,   11,   10],\n","        [   3,    9,    7,   19,   39,  761,   16,    4,   20,   14],\n","        [  11,    6,    1,    3,   23,   11,  893,    1,    8,    1],\n","        [   5,    8,   21,    6,   42,    1,    1,  917,    7,   20],\n","        [   2,    6,    8,   39,   50,    8,   25,    7,  811,   18],\n","        [   5,    5,    1,    8,   52,    5,    7,   35,   33,  858]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/randinit5bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching randinit to bgonly\n","Evaluate ranks and output to ./results_2n_rank/randinit6bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 6 from randinit to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 6 of send_model is: torch.Size([1, 256, 2, 2])\n","Epoch 0, loss 1357.09\n","Epoch 1, loss 493.70\n","Epoch 2, loss 379.52\n","Epoch 3, loss 320.12\n","Epoch 4, loss 289.48\n","Epoch 5, loss 258.55\n","Epoch 6, loss 244.63\n","Epoch 7, loss 229.58\n","Epoch 8, loss 213.86\n","Epoch 9, loss 202.90\n","**** Finished Training ****\n","Change in stitch weights: 2.552992820739746\n","Largest abs weight change: 0.06686346232891083\n","Number of weights changing > 0.1 of that: 31651\n","Number of weight / bias in stitch layer is 256\n","Change in stitch bias: 0.026579655706882477\n","Largest abs bias change: 0.002824530005455017\n","Number of bias changing > 0.1 of that: 233\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 89.64 %\n","Confusion Matrix\n","tensor([[ 917,    0,   11,    0,   12,    5,   19,    6,    7,    3],\n","        [   0, 1113,    6,    2,    3,    1,    6,    0,    4,    0],\n","        [  10,    2,  931,   16,   16,    4,    8,   21,   24,    0],\n","        [   3,    3,   17,  892,    9,   29,    2,   16,   34,    5],\n","        [   3,    4,    4,    0,  886,    5,   16,   22,    5,   37],\n","        [   8,    1,    3,   25,   22,  772,   16,    9,   25,   11],\n","        [   9,    8,    5,    1,   28,   19,  879,    3,    5,    1],\n","        [   5,    7,   20,    7,   37,    3,    0,  917,    7,   25],\n","        [   8,    4,   13,   31,   40,   28,   15,   12,  802,   21],\n","        [  15,    4,    3,    7,   55,   10,   10,   27,   23,  855]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/randinit6bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching randinit to bgonly\n","Evaluate ranks and output to ./results_2n_rank/randinit7bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 7 from randinit to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 7 of send_model is: torch.Size([1, 512, 1, 1])\n","Epoch 0, loss 757.66\n","Epoch 1, loss 383.83\n","Epoch 2, loss 324.41\n","Epoch 3, loss 296.89\n","Epoch 4, loss 280.42\n","Epoch 5, loss 268.04\n","Epoch 6, loss 259.00\n","Epoch 7, loss 253.55\n","Epoch 8, loss 248.62\n","Epoch 9, loss 245.24\n","**** Finished Training ****\n","Change in stitch weights: 1.8899765014648438\n","Largest abs weight change: 0.025467965751886368\n","Number of weights changing > 0.1 of that: 118828\n","Number of weight / bias in stitch layer is 512\n","Change in stitch bias: 0.025922799482941628\n","Largest abs bias change: 0.002015184611082077\n","Number of bias changing > 0.1 of that: 456\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 84.75 %\n","Confusion Matrix\n","tensor([[ 893,    1,   11,    7,    2,   13,   16,   14,   10,   13],\n","        [   0, 1102,    9,    5,    4,    2,    4,    2,    5,    2],\n","        [  18,    3,  850,   51,   18,    4,   23,   24,   27,   14],\n","        [  13,    7,   32,  814,    7,   40,   14,   23,   42,   18],\n","        [   2,    3,   10,    3,  850,    8,   25,   19,    9,   53],\n","        [   7,    5,    5,   38,   23,  711,   33,   14,   39,   17],\n","        [  20,    7,   13,    3,   16,   30,  840,    5,   20,    4],\n","        [   7,   15,   29,    8,   18,    8,    1,  886,    9,   47],\n","        [  12,    6,   27,   61,   34,   48,   34,   17,  687,   48],\n","        [  16,   12,    5,   12,   52,   12,    8,   26,   24,  842]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/randinit7bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","stitching randinit to bgonly\n","Evaluate ranks and output to ./results_2n_rank/randinit8bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","Train the stitch to a model stitched after layer 8 from randinit to bgonly\n","Use the bw data loader (train and test) regardless of what the models were trained on\n","get_layer_output_shape for type='ResNet18'\n","The shape of the output from layer 8 of send_model is: torch.Size([1, 512, 1, 1])\n","Epoch 0, loss 788.53\n","Epoch 1, loss 393.76\n","Epoch 2, loss 329.53\n","Epoch 3, loss 298.88\n","Epoch 4, loss 281.72\n","Epoch 5, loss 268.71\n","Epoch 6, loss 261.18\n","Epoch 7, loss 254.87\n","Epoch 8, loss 249.95\n","Epoch 9, loss 245.55\n","**** Finished Training ****\n","Change in stitch weights: 1.9382985830307007\n","Largest abs weight change: 0.02664303407073021\n","Number of weights changing > 0.1 of that: 116900\n","Number of weight / bias in stitch layer is 512\n","Change in stitch bias: 0.02640492655336857\n","Largest abs bias change: 0.0020157769322395325\n","Number of bias changing > 0.1 of that: 461\n","Test the trained stitch against dataset_type='bw' data\n","Test Accuracy: 84.42 %\n","Confusion Matrix\n","tensor([[ 895,    1,   11,    7,    3,   11,   20,   11,   11,   10],\n","        [   0, 1109,    5,    3,    1,    2,    7,    1,    5,    2],\n","        [  19,    3,  853,   44,   12,    8,   26,   29,   27,   11],\n","        [  16,    9,   35,  811,    8,   36,   20,   18,   38,   19],\n","        [   3,    9,   10,    2,  826,   11,   31,   26,    8,   56],\n","        [  12,    5,    7,   41,   13,  710,   32,   17,   39,   16],\n","        [  20,    8,   18,    5,   14,   31,  835,    6,   18,    3],\n","        [   7,   19,   26,    9,   14,    6,    1,  899,    7,   40],\n","        [  16,    8,   35,   63,   26,   58,   36,   16,  678,   38],\n","        [  17,   11,    4,   16,   48,   16,   12,   31,   28,  826]],\n","       dtype=torch.int32)\n","===================================================================\n","output to ./results_2n_rank/randinit8bgonly-bw-10_2024-08-06_12-57-58_SEED60_EPOCHS4_BGN0.1_exp2e_ResNet18_bg_only_colour_mnist-test.csv\n","NOTE: Only running stitch to bgonly: skipping\n"]}],"source":["logtofile(\"Entering Stitch/Rank\")\n","# logtofile(process.memory_info().rss)  # in bytes\n","\n","logtofile(f\"{device=}\")\n","stitching_accuracies = dict()\n","stitching_penalties = dict()\n","# NOTE this is only valid as all models are the same architecture\n","num_layers_in_model = len(list(process_structure[\"bw\"][\"model\"].children()))\n","for send_key, send_val in process_structure.items():\n","    #if (send_key == \"bgonly\"):\n","    #    logtofile(f\"NOTE: not running stitch from bgonly: skipping\")\n","    #    continue\n","    stitching_accuracies[send_key] = dict()\n","    stitching_penalties[send_key] = dict()\n","    for rcv_key, rcv_val in process_structure.items():\n","        if (rcv_key != \"bgonly\"):\n","            logtofile(f\"NOTE: Only running stitch to bgonly: skipping\")\n","            continue\n","        stitching_accuracies[send_key][rcv_key] = dict()\n","        stitching_penalties[send_key][rcv_key] = dict()\n","        for layer_to_cut_after in range(3,num_layers_in_model - 1):\n","            # for consistency, use the rcv network for the filename stem.\n","            if rcv_val[\"train\"]:\n","                filename = rcv_val[\"saveas\"]\n","            else:\n","                filename = rcv_val[\"loadfrom\"]\n","            print(f\"stitching {send_key} to {rcv_key}\")\n","\n","            rank_filename = filename.split('/')[-1].replace('.weights', '-test.csv')\n","            # denote output name as <model_training_type>-dataset-<name>\n","            # where <model_training_type> is [sender_model or X][layer_to_cut_after][Receiver_model]\n","            model_training_type = f\"{send_key}{layer_to_cut_after}{rcv_key}\"\n","\n","            dataset_type = \"bw\" # ALWAYS use this dataset in this test\n","            outpath = f\"./{results_root}_rank/{model_training_type}-{dataset_type}-{seed}_{rank_filename}\"\n","\n","            if os.path.exists(f\"{outpath}\"):\n","                logtofile(f\"Already evaluated for {outpath}\")\n","                continue\n","            ####################################################################################\n","            logtofile(f\"Evaluate ranks and output to {outpath}\")\n","            # logtofile(process.memory_info().rss)  # in bytes\n","\n","            logtofile(f\"Train the stitch to a model stitched after layer {layer_to_cut_after} from {send_key} to {rcv_key}\")\n","            logtofile(f\"Use the {dataset_type} data loader (train and test) regardless of what the models were trained on\")\n","\n","            # train a stitch on the unbiased_colour dataset to compare receiver network performance with stitched\n","            model_stitched = StitchedResNet18(send_model=send_val[\"model\"],\n","                                              after_layer_index=layer_to_cut_after,\n","                                              rcv_model=rcv_val[\"model\"],\n","                                              input_image_shape=colour_mnist_shape, device=device  ).to(device)\n","\n","            #############################################################\n","            # store the initial stitch state\n","            initial_stitch_weight = model_stitched.stitch.s_conv1.weight.clone()\n","            initial_stitch_bias   = model_stitched.stitch.s_conv1.bias.clone()\n","            stitch_initial_weight_outpath    = f\"./{results_root}/STITCH_initial_weight_{model_training_type}-{dataset_type}-{seed}_{filename.split('/')[-1]}\"\n","            stitch_initial_bias_outpath      = f\"./{results_root}/STITCH_initial_bias_{model_training_type}-{dataset_type}-{seed}_{filename.split('/')[-1]}\"\n","            if save_stitch_delta:\n","                torch.save(initial_stitch_weight, stitch_initial_weight_outpath)\n","                torch.save(initial_stitch_bias, stitch_initial_bias_outpath)\n","            ############################################################\n","\n","            # define the loss function and the optimiser\n","            loss_function = nn.CrossEntropyLoss()\n","            # Hernandez said : momentum 0.9, batch size 256, weight decay 0.01, learning rate 0.01, and a post-warmup cosine learning rate scheduler.\n","            # optimiser = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n","            optimiser = optim.SGD(model_stitched.parameters(), lr=1e-4, momentum=0.9, weight_decay=0.01)\n","\n","            # Put top model into train mode so that bn and dropout perform in training mode\n","            model_stitched.train()\n","            # Freeze the whole model\n","            model_stitched.requires_grad_(False)\n","            # Un-Freeze the stitch layer\n","            for name, param in model_stitched.stitch.named_parameters():\n","                param.requires_grad_(True)\n","            # the epoch loop: note that we're training the whole network\n","            for epoch in range(stitch_train_epochs):\n","                running_loss = 0.0\n","                for data in process_structure[dataset_type][\"train_loader\"]:\n","                    # data is (representations, labels) tuple\n","                    # get the inputs and put them on the GPU\n","                    inputs, labels = data\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n","\n","                    # zero the parameter gradients\n","                    optimiser.zero_grad()\n","\n","                    # forward + loss + backward + optimise (update weights)\n","                    outputs = model_stitched(inputs)\n","                    loss = loss_function(outputs, labels)\n","                    loss.backward()\n","                    optimiser.step()\n","\n","                    # keep track of the loss this epoch\n","                    running_loss += loss.item()\n","                logtofile(\"Epoch %d, loss %4.2f\" % (epoch, running_loss))\n","                # logtofile(process.memory_info().rss)  # in bytes\n","\n","            logtofile('**** Finished Training ****')\n","\n","            model_stitched.eval() # ALWAYS DO THIS BEFORE YOU EVALUATE MODELS\n","\n","            ############################################################\n","            # store the trained stitch\n","            trained_stitch_weight = model_stitched.stitch.s_conv1.weight.clone()\n","            trained_stitch_bias   = model_stitched.stitch.s_conv1.bias.clone()\n","            stitch_trained_weight_outpath    = f\"./{results_root}/STITCH_trained_weight_{model_training_type}-{dataset_type}-{seed}_{filename.split('/')[-1]}\"\n","            stitch_trained_bias_outpath      = f\"./{results_root}/STITCH_trained_bias_{model_training_type}-{dataset_type}-{seed}_{filename.split('/')[-1]}\"\n","\n","            if save_stitch_delta:\n","                torch.save(trained_stitch_weight, stitch_trained_weight_outpath)\n","                torch.save(trained_stitch_bias, stitch_trained_bias_outpath)\n","\n","            stitch_weight_diff = trained_stitch_weight - initial_stitch_weight\n","            stitch_weight_delta = torch.linalg.norm(stitch_weight_diff).item()\n","            logtofile(f\"Change in stitch weights: {stitch_weight_delta}\")\n","            maxabsweight =  torch.max(stitch_weight_diff.abs()).item()\n","            logtofile(f\"Largest abs weight change: {maxabsweight}\")\n","            stitch_weight_number = torch.sum(torch.where(stitch_weight_diff.abs() > 0.1*maxabsweight, True, False)).item()\n","            logtofile(f\"Number of weights changing > 0.1 of that: {stitch_weight_number}\")\n","\n","\n","            print(f\"Number of weight / bias in stitch layer is {len(initial_stitch_weight)}\")\n","            stitch_bias_diff = trained_stitch_bias - initial_stitch_bias\n","            stitch_bias_delta = torch.linalg.norm(stitch_bias_diff).item()\n","            logtofile(f\"Change in stitch bias: {stitch_bias_delta}\")\n","            maxabsbias =  torch.max(stitch_bias_diff.abs()).item()\n","            logtofile(f\"Largest abs bias change: {maxabsbias}\")\n","            stitch_bias_number = torch.sum(torch.where(stitch_bias_diff.abs() > 0.1*maxabsbias, True, False)).item()\n","            logtofile(f\"Number of bias changing > 0.1 of that: {stitch_bias_number}\")\n","            ##############################################################\n","\n","\n","            # Compute the model accuracy on the test set\n","            correct = 0\n","            total = 0\n","\n","            # assuming 10 classes\n","            # rows represent actual class, columns are predicted\n","            confusion_matrix = torch.zeros(10,10, dtype=torch.int)\n","            TDL = process_structure[dataset_type][\"test_loader\"]\n","            for data in TDL:\n","                inputs, labels = data\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                predictions = torch.argmax(model_stitched(inputs),1)\n","                matches = predictions == labels.to(device)\n","                correct += matches.sum().item()\n","                total += len(labels)\n","\n","                for idx, l in enumerate(labels):\n","                    confusion_matrix[l, predictions[idx]] = 1 + confusion_matrix[l, predictions[idx]]\n","            logtofile(f\"Test the trained stitch against {dataset_type=} data\")\n","            acc =  ((100.0 * correct) / total)\n","            logtofile('Test Accuracy: %2.2f %%' % acc)\n","            logtofile('Confusion Matrix')\n","            logtofile(confusion_matrix)\n","            logtofile(\"===================================================================\")\n","            # logtofile(process.memory_info().rss)  # in bytes\n","\n","            # Stitching penalty should be negative if there is an improvement, and is relative to the original receiver network\n","            stitching_accuracies[send_key][rcv_key][layer_to_cut_after] = acc\n","            stitching_penalties[send_key][rcv_key][layer_to_cut_after] = original_accuracy[rcv_key] - acc\n","\n","            if measure_rank:\n","              # MEASURE RANK\n","              #TDL = biased_test_dataloader\n","              params = {}\n","              params[\"model\"] = model_training_type # a mnemonic\n","              params[\"dataset\"] = dataset_type\n","              params[\"seed\"] = seed\n","              if send_val[\"train\"]:\n","                  params[\"send_file\"] = send_val[\"saveas\"]\n","              else:\n","                  params[\"send_file\"] = send_val[\"loadfrom\"]\n","              if rcv_val[\"train\"]:\n","                  params[\"rcv_file\"] = rcv_val[\"saveas\"]\n","              else:\n","                  params[\"rcv_file\"] = rcv_val[\"loadfrom\"]\n","              params[\"stitch_weight_delta\"] = stitch_weight_delta\n","              params[\"stitch_bias_delta\"] = stitch_bias_delta\n","              params[\"stitch_weight_number\"] = stitch_weight_number\n","              params[\"stitch_bias_number\"] = stitch_bias_number\n","              # logtofile(process.memory_info().rss)  # in bytes\n","              with torch.no_grad():\n","                  layers, features, handles = install_hooks(model_stitched)\n","                  metrics = evaluate_model(model_stitched, TDL, 'acc', verbose=2)\n","                  params.update(metrics)\n","\n","                  classes = None\n","                  df = perform_analysis(features, classes, layers, params, n=-1)\n","                  df.to_csv(f\"{outpath}\")\n","\n","              for h in handles:\n","                  h.remove()\n","              del model_stitched, layers, features, metrics, params, df, handles\n","              gc.collect()\n","              # logtofile(process.memory_info().rss)  # in bytes\n","            else:\n","              dl = TDL\n","\n","            print(f\"output to {outpath}\")\n","\n","            params = {}\n","            params[\"model\"] = model_training_type\n","            params[\"dataset\"] = dataset_type\n","            params[\"seed\"] = seed\n","            if val[\"train\"]: # as only one network used, record its filename as both send and receive files\n","                params[\"send_file\"] = val[\"saveas\"]\n","                params[\"rcv_file\"] = val[\"saveas\"]\n","            else:\n","                params[\"send_file\"] = val[\"loadfrom\"]\n","                params[\"rcv_file\"] = val[\"loadfrom\"]\n","            params[\"val_acc\"] = acc / 100\n","            params[\"name\"] = \"only\"\n","\n","            results = []\n","            results.append(params)\n","            df = pd.DataFrame.from_records(results)\n","            df.to_csv(f\"{outpath}\")\n","\n","            del  params, df\n","            gc.collect()\n","\n"]},{"cell_type":"code","execution_count":18,"id":"3db5808a-6351-4133-9e7c-85e8e9248cfb","metadata":{"id":"3db5808a-6351-4133-9e7c-85e8e9248cfb","outputId":"c2a374b1-d22a-4eb1-cfa0-115bae88156e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747516891676,"user_tz":-60,"elapsed":10,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["stitching_accuracies={'bw': {'bgonly': {3: 85.1, 4: 94.1, 5: 98.35, 6: 98.94, 7: 99.2, 8: 99.19}}, 'bgonly': {'bgonly': {3: 70.23, 4: 83.27, 5: 88.53, 6: 83.75, 7: 53.38, 8: 54.98}}, 'randinit': {'bgonly': {3: 79.54, 4: 85.02, 5: 89.66, 6: 89.64, 7: 84.75, 8: 84.42}}}\n","stitching_penalties={'bw': {'bgonly': {3: 14.900000000000006, 4: 5.900000000000006, 5: 1.6500000000000057, 6: 1.0600000000000023, 7: 0.7999999999999972, 8: 0.8100000000000023}}, 'bgonly': {'bgonly': {3: 29.769999999999996, 4: 16.730000000000004, 5: 11.469999999999999, 6: 16.25, 7: 46.62, 8: 45.02}}, 'randinit': {'bgonly': {3: 20.459999999999994, 4: 14.980000000000004, 5: 10.340000000000003, 6: 10.36, 7: 15.25, 8: 15.579999999999998}}}\n"]}],"source":["logtofile(f\"{stitching_accuracies=}\")\n","logtofile(f\"{stitching_penalties=}\")"]},{"cell_type":"code","execution_count":19,"id":"cd669a19-7c42-4265-b8e8-57165995c097","metadata":{"id":"cd669a19-7c42-4265-b8e8-57165995c097","outputId":"cbcdbe30-e0a4-4667-f5e7-ad3cc3fc1047","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747516891745,"user_tz":-60,"elapsed":60,"user":{"displayName":"Damian Smith","userId":"13736799635312870126"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["bw-bgonly\n","original_accuracy[r_key]=100.0\n","Stitch Accuracy\n","L3: 85.1\n","L4: 94.1\n","L5: 98.35\n","L6: 98.94\n","L7: 99.2\n","L8: 99.19\n","--------------------------\n","bgonly-bgonly\n","original_accuracy[r_key]=100.0\n","Stitch Accuracy\n","L3: 70.23\n","L4: 83.27\n","L5: 88.53\n","L6: 83.75\n","L7: 53.38\n","L8: 54.98\n","--------------------------\n","randinit-bgonly\n","original_accuracy[r_key]=100.0\n","Stitch Accuracy\n","L3: 79.54\n","L4: 85.02\n","L5: 89.66\n","L6: 89.64\n","L7: 84.75\n","L8: 84.42\n","--------------------------\n"]}],"source":["for s_key in stitching_accuracies:\n","    for r_key in stitching_accuracies[s_key]:\n","        logtofile(f\"{s_key}-{r_key}\")\n","        logtofile(f\"{original_accuracy[r_key]=}\")\n","        logtofile(\"Stitch Accuracy\")\n","        for layer in stitching_accuracies[s_key][r_key]:\n","            logtofile(f\"L{layer}: {stitching_accuracies[s_key][r_key][layer]}\")\n","        logtofile(\"--------------------------\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"provenance":[{"file_id":"1ysf_0Ampz4dhyHGkMPz7J_F5cFzMlJEf","timestamp":1747511186409},{"file_id":"11J4lFGrFJRjXnTylcrvfJd6lbr5Buvk4","timestamp":1747391804400}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}