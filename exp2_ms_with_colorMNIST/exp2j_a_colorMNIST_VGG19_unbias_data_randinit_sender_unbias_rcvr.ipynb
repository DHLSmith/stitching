{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb427423-0eab-4440-b27a-05a5ee8d9e9b",
   "metadata": {},
   "source": [
    "# To investigate model-stitching analysis on VGG19\n",
    "Stitch randomly initialised model into VGG19 unbias receiver - based on exp2j which self-stitched models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fc60f8-f6f6-469c-8705-c9015bd43951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import gc\n",
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "from torch.linalg import LinAlgError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import datetime\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# add the path to find colour_mnist\n",
    "sys.path.append(os.path.abspath('../ReferenceCode'))\n",
    "import colour_mnist\n",
    "from stitch_utils import train_model, StitchedVGG19, get_layer_output_shape\n",
    "from stitch_utils import generate_activations, SyntheticDataset\n",
    "import stitch_utils\n",
    "\n",
    "# add the path to find the rank analysis code\n",
    "# https://github.com/DHLSmith/jons-tunnel-effect/tree/NeurIPSPaper\n",
    "\n",
    "sys.path.append(os.path.abspath('../../jons-tunnel-effect/'))\n",
    "from utils.modelfitting import evaluate_model, set_seed\n",
    "from extract_weight_rank import install_hooks, perform_analysis\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "def logtofile(log_text, verbose=True):\n",
    "    if verbose:\n",
    "        print(log_text)\n",
    "    with open(save_log_as, \"a\") as f:    \n",
    "        print(log_text, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6761870b-2996-4763-8d90-76529ec5822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 107\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "train_all = False\n",
    "save_stitch_delta = False\n",
    "measure_rank = False\n",
    "\n",
    "results_root = \"results_2j_a\"\n",
    "\n",
    "# randinit model\n",
    "gen_randinit_model = True\n",
    "randinit_model_to_load = None\n",
    "\n",
    "# MIX is 1/3 bgonly, 1/3 mnist only, 1/3 biased data\n",
    "train_mix_mnist_model = train_all\n",
    "mix_mnist_model_to_load = '../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_mix_mnist.weights'\n",
    "\n",
    "# BW is greyscale mnist with no colour added (i.e. original mnist)\n",
    "train_bw_mnist_model = train_all  # when False, automatically loads a trained model\n",
    "bw_mnist_model_to_load = '../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_bw_mnist.weights'\n",
    "\n",
    "# BG_ONLY contains no mnist data, just a coloured background\n",
    "train_bg_only_colour_mnist_model = train_all # when False, automatically loads a trained model\n",
    "bg_only_colour_mnist_model_to_load     =  '../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_bg_only_colour_mnist.weights'\n",
    "#bg_only_std_colour_mnist_model_to_load =  '../exp1_ms_with_random_dataset/results_1g/2024-08-10_22-57-13_SEED104_EPOCHS50_BGN0.1_exp1g_VGG19_bg_only_colour_mnist.weights'\n",
    "\n",
    "# BG_UNBIASED is digits with randomly selected colour background. Targets represent the colour\n",
    "train_bg_unbiased_colour_mnist_model = train_all  # when False, automatically loads a trained model\n",
    "bg_unbiased_colour_mnist_model_to_load     = '../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_bg_unbiased_colour_mnist.weights'\n",
    "#bg_unbiased_std_colour_mnist_model_to_load = '../exp1_ms_with_random_dataset/results_1g/2024-08-11_11-32-44_SEED104_EPOCHS50_BGN0.1_exp1g_VGG19_bg_unbiased_colour_mnist.weights'\n",
    "\n",
    "# BIASED is digits with consistent per-class colour background. \n",
    "train_biased_colour_mnist_model = train_all  # when False, automatically loads a trained model\n",
    "biased_colour_mnist_model_to_load = '../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_biased_colour_mnist.weights'\n",
    "\n",
    "# UNBIASED is digits with randoly selected colour background. Targets are digit values\n",
    "train_unbiased_colour_mnist_model = train_all  # when False, automatically loads a trained model\n",
    "unbiased_colour_mnist_model_to_load = '../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist.weights'\n",
    "\n",
    "original_train_epochs = 50\n",
    "bg_noise = 0.1\n",
    "synthetic_dataset_noise = 0.1\n",
    "\n",
    "stitch_train_epochs = 50\n",
    "#stitch_train_loss_tol = 40\n",
    "\n",
    "device = 'cuda:3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ee6e98-a6f2-4647-b378-5f7b1af48581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed at 2025-03-26_18-57-22\n",
      "logging to ./results_2j_a/2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_log.txt\n",
      "seed=107\n",
      "bg_noise=0.1\n",
      "synthetic_dataset_noise=0.1\n",
      "gen_randinit_model=True\n",
      "save_randinit_model_as='./results_2j_a/2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit.weights'\n",
      "train_mix_mnist_model=False\n",
      "mix_mnist_model_to_load='../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_mix_mnist.weights'\n",
      "train_bw_mnist_model=False\n",
      "bw_mnist_model_to_load='../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_bw_mnist.weights'\n",
      "train_bg_only_colour_mnist_model=False\n",
      "bg_only_colour_mnist_model_to_load='../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_bg_only_colour_mnist.weights'\n",
      "train_bg_unbiased_colour_mnist_model=False\n",
      "bg_unbiased_colour_mnist_model_to_load='../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_bg_unbiased_colour_mnist.weights'\n",
      "train_biased_colour_mnist_model=False\n",
      "biased_colour_mnist_model_to_load='../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_biased_colour_mnist.weights'\n",
      "train_unbiased_colour_mnist_model=False\n",
      "unbiased_colour_mnist_model_to_load='../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist.weights'\n",
      "stitch_train_epochs=50\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate filenames and log the setup details\n",
    "formatted_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "filename_prefix = f\"./{results_root}/{formatted_time}_SEED{seed}_EPOCHS{original_train_epochs}_BGN{bg_noise}_exp2h_VGG19\"\n",
    "save_mix_mnist_model_as = f\"{filename_prefix}_mix_mnist.weights\"\n",
    "save_bw_mnist_model_as = f\"{filename_prefix}_bw_mnist.weights\"\n",
    "save_bg_only_colour_mnist_model_as = f\"{filename_prefix}_bg_only_colour_mnist.weights\"\n",
    "save_bg_unbiased_colour_mnist_model_as = f\"{filename_prefix}_bg_unbiased_colour_mnist.weights\"\n",
    "save_biased_colour_mnist_model_as = f\"{filename_prefix}_biased_colour_mnist.weights\"\n",
    "save_unbiased_colour_mnist_model_as = f\"{filename_prefix}_unbiased_colour_mnist.weights\"\n",
    "save_randinit_model_as = f\"{filename_prefix}_randinit.weights\"\n",
    "\n",
    "save_log_as = f\"{filename_prefix}_log.txt\"\n",
    "\n",
    "colour_mnist_shape = (3,28,28)\n",
    "vgg19_input_shape = (3,32,32) # monochrome\n",
    "\n",
    "logtofile(f\"Executed at {formatted_time}\")\n",
    "logtofile(f\"logging to {save_log_as}\")\n",
    "logtofile(f\"{seed=}\")\n",
    "logtofile(f\"{bg_noise=}\")\n",
    "logtofile(f\"{synthetic_dataset_noise=}\")\n",
    "\n",
    "logtofile(f\"{gen_randinit_model=}\")\n",
    "if gen_randinit_model:\n",
    "    logtofile(f\"{save_randinit_model_as=}\")    \n",
    "else:\n",
    "    logtofile(f\"{randinit_model_to_load=}\")\n",
    "\n",
    "logtofile(f\"{train_mix_mnist_model=}\")\n",
    "if train_mix_mnist_model:\n",
    "    logtofile(f\"{save_mix_mnist_model_as=}\")\n",
    "    logtofile(f\"{original_train_epochs=}\")\n",
    "else:\n",
    "    logtofile(f\"{mix_mnist_model_to_load=}\")\n",
    "\n",
    "logtofile(f\"{train_bw_mnist_model=}\")\n",
    "if train_bw_mnist_model:\n",
    "    logtofile(f\"{save_bw_mnist_model_as=}\")\n",
    "    logtofile(f\"{original_train_epochs=}\")\n",
    "else:\n",
    "    logtofile(f\"{bw_mnist_model_to_load=}\")\n",
    "    \n",
    "logtofile(f\"{train_bg_only_colour_mnist_model=}\")\n",
    "if train_bg_only_colour_mnist_model:\n",
    "    logtofile(f\"{save_bg_only_colour_mnist_model_as=}\")\n",
    "    logtofile(f\"{original_train_epochs=}\")\n",
    "else:\n",
    "    logtofile(f\"{bg_only_colour_mnist_model_to_load=}\")\n",
    "    \n",
    "logtofile(f\"{train_bg_unbiased_colour_mnist_model=}\")\n",
    "if train_bg_unbiased_colour_mnist_model:\n",
    "    logtofile(f\"{save_bg_unbiased_colour_mnist_model_as=}\")\n",
    "    logtofile(f\"{original_train_epochs=}\")\n",
    "else:\n",
    "    logtofile(f\"{bg_unbiased_colour_mnist_model_to_load=}\")\n",
    "\n",
    "logtofile(f\"{train_biased_colour_mnist_model=}\")\n",
    "if train_biased_colour_mnist_model:\n",
    "    logtofile(f\"{save_biased_colour_mnist_model_as=}\")\n",
    "    logtofile(f\"{original_train_epochs=}\")\n",
    "else:\n",
    "    logtofile(f\"{biased_colour_mnist_model_to_load=}\")\n",
    "\n",
    "logtofile(f\"{train_unbiased_colour_mnist_model=}\")\n",
    "if train_unbiased_colour_mnist_model:\n",
    "    logtofile(f\"{save_unbiased_colour_mnist_model_as=}\")\n",
    "    logtofile(f\"{original_train_epochs=}\")\n",
    "else:\n",
    "    logtofile(f\"{unbiased_colour_mnist_model_to_load=}\")\n",
    "\n",
    "logtofile(f\"{stitch_train_epochs=}\")\n",
    "logtofile(f\"================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc621f6-55e8-4191-8288-dc2493cd6bff",
   "metadata": {},
   "source": [
    "mnist and cifar-10 both use 10-classes, with 60_000 train samples and 10_000 test samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34a54d2-c8fa-4f51-8809-7a40b4fefc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataloaders\n",
    "transform_resize=transforms.Resize(vgg19_input_shape[2])\n",
    "transform_bw = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to 3 channels \n",
    "    transform_resize,\n",
    "    transforms.ToTensor(),  # convert to tensor. We always do this one    \n",
    "    transforms.Normalize((0.1307,) * 3, (0.3081,) * 3)     \n",
    "])\n",
    "\n",
    "\n",
    "mnist_train = MNIST(\"./MNIST\", train=True, download=True, transform=transform_bw)\n",
    "mnist_test = MNIST(\"./MNIST\", train=False, download=True, transform=transform_bw)\n",
    "\n",
    "bw_train_dataloader = DataLoader(mnist_train, batch_size=64, shuffle=True, drop_last=True)\n",
    "bw_test_dataloader  = DataLoader(mnist_test,  batch_size=64, shuffle=True, drop_last=False)\n",
    "\n",
    "# mix dataloader\n",
    "mix_train_dataloader = colour_mnist.get_mixed_mnist_dataloader(root=\"./MNIST\", batch_size=64, train=True, bg_noise_level=bg_noise, standard_getitem=True, dl_transform=transform_resize)\n",
    "mix_test_dataloader = colour_mnist.get_mixed_mnist_dataloader(root=\"./MNIST\", batch_size=64,  train=False, bg_noise_level=bg_noise, standard_getitem=True, dl_transform=transform_resize)\n",
    "\n",
    "# bg_only means no digits - we will use colour as label\n",
    "bg_only_train_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=64, data_label_correlation=1.0, train=True, bg_noise_level=bg_noise, bg_only=True, standard_getitem=True, dl_transform=transform_resize)\n",
    "bg_only_test_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=64, data_label_correlation=1.0, train=False, bg_noise_level=bg_noise, bg_only=True, standard_getitem=True, dl_transform=transform_resize)\n",
    "\n",
    "# unbiased means each digit has correct label and random colour - but bg means we will use colour as label (i.e. the bias_target will be the target)\n",
    "bg_unbiased_train_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=64, data_label_correlation=0.1, train=True, bg_noise_level=bg_noise, bias_targets_as_targets=True, dl_transform=transform_resize)\n",
    "bg_unbiased_test_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=64, data_label_correlation=0.1, train=False, bg_noise_level=bg_noise, bias_targets_as_targets=True, dl_transform=transform_resize)\n",
    "\n",
    "# biased means each digit has correct label and consistent colour - Expect network to learn the colours only\n",
    "biased_train_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=64, data_label_correlation=1.0, train=True, bg_noise_level=bg_noise, standard_getitem=True, dl_transform=transform_resize)\n",
    "biased_test_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=64, data_label_correlation=1.0, train=False, bg_noise_level=bg_noise, standard_getitem=True, dl_transform=transform_resize)\n",
    "\n",
    "# unbiased means each digit has correct label and random colour - Expect network to disregard colours?\n",
    "unbiased_train_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=64, data_label_correlation=0.1, train=True, bg_noise_level=bg_noise, standard_getitem=True, dl_transform=transform_resize)\n",
    "unbiased_test_dataloader = colour_mnist.get_biased_mnist_dataloader(root=\"./MNIST\", batch_size=64, data_label_correlation=0.1, train=False, bg_noise_level=bg_noise, standard_getitem=True, dl_transform=transform_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24842d82-5f62-4d1b-acc5-d1997a08b0b9",
   "metadata": {},
   "source": [
    "## Set up VGG19 models and train it on versions of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf635cfd-a9ad-4e37-98a0-80d0db2a3b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for key='randinit'\n",
      "model has already been initialised: save it as ./results_2j_a/2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit.weights\n",
      "Processing for key='unbias'\n",
      "val['loadfrom']='../exp1_ms_with_random_dataset/results_1g/2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist.weights'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process_structure = dict()\n",
    "\n",
    "\n",
    "process_structure[\"randinit\"]    = dict()\n",
    "process_structure[\"unbias\"]    = dict()\n",
    "\n",
    "# \"randinit\"\n",
    "process_structure[\"randinit\"][\"model\"] = torchvision.models.vgg19(weights=None, num_classes=10).to(device) # Untrained model\n",
    "process_structure[\"randinit\"][\"train\"] = gen_randinit_model \n",
    "process_structure[\"randinit\"][\"train_loader\"] = unbiased_train_dataloader\n",
    "process_structure[\"randinit\"][\"test_loader\"] = unbiased_test_dataloader  # by default, test it against the unbias data set\n",
    "process_structure[\"randinit\"][\"saveas\"] = save_randinit_model_as\n",
    "process_structure[\"randinit\"][\"loadfrom\"] =  randinit_model_to_load\n",
    "\n",
    "# \"unbiased_colour_mnist\"\n",
    "process_structure[\"unbias\"][\"model\"] = torchvision.models.vgg19(weights=None, num_classes=10).to(device) # Untrained model\n",
    "process_structure[\"unbias\"][\"train\"] = train_unbiased_colour_mnist_model\n",
    "process_structure[\"unbias\"][\"train_loader\"] = unbiased_train_dataloader\n",
    "process_structure[\"unbias\"][\"test_loader\"] = unbiased_test_dataloader\n",
    "process_structure[\"unbias\"][\"saveas\"] = save_unbiased_colour_mnist_model_as\n",
    "process_structure[\"unbias\"][\"loadfrom\"] =  unbiased_colour_mnist_model_to_load\n",
    "\n",
    "for key, val in process_structure.items():\n",
    "    print(f\"Processing for {key=}\")\n",
    "    if key == \"randinit\":\n",
    "        if gen_randinit_model:  # create new model but don't train it\n",
    "            logtofile(f\"model has already been initialised: save it as {val['saveas']}\")\n",
    "            torch.save(val[\"model\"].state_dict(), val[\"saveas\"])\n",
    "        else:\n",
    "            logtofile(f\"{val['loadfrom']=}\")\n",
    "            val[\"model\"].load_state_dict(torch.load(val[\"loadfrom\"], map_location=torch.device(device)))\n",
    "    else:\n",
    "        if val[\"train\"]:\n",
    "            train_model(model=val[\"model\"], train_loader=val[\"train_loader\"], \n",
    "                        epochs=original_train_epochs, saveas=val[\"saveas\"], \n",
    "                        description=key, device=device, logtofile=logtofile,                     \n",
    "                        milestones=[100,150],\n",
    "                        lr=0.01, #0.1 didn't work for some datasets                    \n",
    "                       )\n",
    "        else:\n",
    "            logtofile(f\"{val['loadfrom']=}\")\n",
    "            val[\"model\"].load_state_dict(torch.load(val[\"loadfrom\"], map_location=torch.device(device)))\n",
    "    val[\"model\"].eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b169c5c7-7929-48e1-82eb-6f047aa4e5f2",
   "metadata": {},
   "source": [
    "## Measure the Accuracy, Record the Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbb925a-269d-4027-9500-6cdce4de9d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Calculation for VGG19 with key='randinit'\n",
      "Test the Trained VGG19\n",
      "Test Accuracy: 10.32 %\n",
      "Confusion Matrix\n",
      "tensor([[   0,    0,  980,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0, 1135,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0, 1032,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0, 1010,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,  982,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,  892,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,  958,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0, 1028,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,  974,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0, 1009,    0,    0,    0,    0,    0,    0,    0]],\n",
      "       dtype=torch.int32)\n",
      "tensor(10000)\n",
      "output to ./results_2j_a_rank/randinit-randinit-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "Accuracy Calculation for VGG19 with key='unbias'\n",
      "Test the Trained VGG19\n",
      "Test Accuracy: 98.32 %\n",
      "Confusion Matrix\n",
      "tensor([[ 975,    0,    0,    0,    0,    0,    1,    1,    2,    1],\n",
      "        [   0, 1123,    2,    1,    1,    0,    2,    1,    5,    0],\n",
      "        [   3,    0, 1021,    0,    0,    0,    0,    4,    4,    0],\n",
      "        [   0,    0,    2, 1002,    0,    1,    0,    1,    3,    1],\n",
      "        [   0,    0,    2,    0,  949,    0,    3,    2,    1,   25],\n",
      "        [   2,    1,    0,   10,    0,  870,    1,    1,    3,    4],\n",
      "        [   5,    3,    0,    1,    2,    4,  942,    0,    1,    0],\n",
      "        [   1,    2,    3,    1,    0,    0,    0, 1013,    1,    7],\n",
      "        [   2,    0,    3,    5,    1,    3,    0,    2,  954,    4],\n",
      "        [   3,    3,    0,    8,    4,    2,    0,    6,    0,  983]],\n",
      "       dtype=torch.int32)\n",
      "tensor(10000)\n",
      "output to ./results_2j_a_rank/unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "original_accuracy={'randinit': 10.32, 'unbias': 98.32}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "original_accuracy = dict()\n",
    "for key, val in process_structure.items():\n",
    "    logtofile(f\"Accuracy Calculation for VGG19 with {key=}\")\n",
    "    model = val[\"model\"]\n",
    "    model.eval() # ALWAYS DO THIS BEFORE YOU EVALUATE MODELS\n",
    "    \n",
    "    # Compute the model accuracy on the test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # assuming 10 classes\n",
    "    # rows represent actual class, columns are predicted\n",
    "    confusion_matrix = torch.zeros(10,10, dtype=torch.int)\n",
    "    \n",
    "    for data in val[\"test_loader\"]:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predictions = torch.argmax(model(inputs),1)\n",
    "        \n",
    "        matches = predictions == labels\n",
    "        correct += matches.sum().item()\n",
    "        total += len(labels)\n",
    "        for idx, l in enumerate(labels):\n",
    "            confusion_matrix[l, predictions[idx]] = 1 + confusion_matrix[l, predictions[idx]] \n",
    "    \n",
    "    logtofile(\"Test the Trained VGG19\")\n",
    "    acc = ((100.0 * correct) / total)\n",
    "    logtofile('Test Accuracy: %2.2f %%' % acc)\n",
    "    original_accuracy[key] = acc\n",
    "    logtofile('Confusion Matrix')\n",
    "    logtofile(confusion_matrix)\n",
    "    logtofile(confusion_matrix.sum())\n",
    "\n",
    "    if not measure_rank:\n",
    "        \n",
    "        dl = val[\"test_loader\"]\n",
    "        \n",
    "        if val[\"train\"]:\n",
    "            filename = val[\"saveas\"] \n",
    "        else:    \n",
    "            filename = val[\"loadfrom\"] \n",
    "        assert os.path.exists(filename)\n",
    "    \n",
    "        #model = torchvision.models.vgg19(weights=None, num_classes=10)  # Untrained model\n",
    "    \n",
    "        #state = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "        #model.load_state_dict(state, assign=True)\n",
    "        #model = model.to(device)\n",
    "                      \n",
    "        #model = RcvVGG19(model, -1, vgg19_input_shape, device).to(device)\n",
    "        out_filename = filename.split('/')[-1].replace('.weights', '-test.csv')\n",
    "        \n",
    "        outpath = f\"./{results_root}_rank/{key}-{key}-{seed}_{out_filename}\"  # denote output name as <model_training_type>-dataset-<name>\n",
    "        \n",
    "        if os.path.exists(f\"{outpath}\"):\n",
    "            logtofile(f\"Already evaluated for {outpath}\")\n",
    "            continue\n",
    "        #logtofile(f\"Measure Rank for {key=}\")\n",
    "        print(f\"output to {outpath}\")\n",
    "                \n",
    "        params = {}\n",
    "        params[\"model\"] = key\n",
    "        params[\"dataset\"] = key\n",
    "        params[\"seed\"] = seed\n",
    "        if val[\"train\"]: # as only one network used, record its filename as both send and receive files\n",
    "            params[\"send_file\"] = val[\"saveas\"] \n",
    "            params[\"rcv_file\"] = val[\"saveas\"] \n",
    "        else:    \n",
    "            params[\"send_file\"] = val[\"loadfrom\"] \n",
    "            params[\"rcv_file\"] = val[\"loadfrom\"]\n",
    "        params[\"val_acc\"] = acc / 100\n",
    "        params[\"name\"] = \"only\"\n",
    "\n",
    "        results = []\n",
    "        results.append(params)\n",
    "        df = pd.DataFrame.from_records(results)\n",
    "        df.to_csv(f\"{outpath}\")\n",
    "                    \n",
    "        del  params, df\n",
    "        gc.collect()\n",
    "\n",
    "logtofile(f\"{original_accuracy=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da373b34-fe35-4256-a9e0-1040f699d45d",
   "metadata": {},
   "source": [
    "## Measure Rank with original dataloader (test) before cutting and stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4f74591-2a3f-4521-8aec-32c324125a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Whole Model - but we will pass it through the RcvResNet18 function to get matching feature names\n",
    "if measure_rank:\n",
    "    for key, val in process_structure.items():\n",
    "        \n",
    "        dl = val[\"test_loader\"]\n",
    "        \n",
    "        if val[\"train\"]:\n",
    "            filename = val[\"saveas\"] \n",
    "        else:    \n",
    "            filename = val[\"loadfrom\"] \n",
    "        assert os.path.exists(filename)\n",
    "    \n",
    "        model = torchvision.models.vgg19(weights=None, num_classes=10)  # Untrained model\n",
    "    \n",
    "        state = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "        model.load_state_dict(state, assign=True)\n",
    "        model = model.to(device)\n",
    "                      \n",
    "        model = RcvVGG19(model, -1, vgg19_input_shape, device).to(device)\n",
    "        out_filename = filename.split('/')[-1].replace('.weights', '-test.csv')\n",
    "        \n",
    "        outpath = f\"./{results_root}_rank/{key}-{key}-{seed}_{out_filename}\"  # denote output name as <model_training_type>-dataset-<name>\n",
    "        \n",
    "        if os.path.exists(f\"{outpath}\"):\n",
    "            logtofile(f\"Already evaluated for {outpath}\")\n",
    "            continue\n",
    "        logtofile(f\"Measure Rank for {key=}\")\n",
    "        print(f\"output to {outpath}\")\n",
    "                \n",
    "        params = {}\n",
    "        params[\"model\"] = key\n",
    "        params[\"dataset\"] = key\n",
    "        params[\"seed\"] = seed\n",
    "        if val[\"train\"]: # as only one network used, record its filename as both send and receive files\n",
    "            params[\"send_file\"] = val[\"saveas\"] \n",
    "            params[\"rcv_file\"] = val[\"saveas\"] \n",
    "        else:    \n",
    "            params[\"send_file\"] = val[\"loadfrom\"] \n",
    "            params[\"rcv_file\"] = val[\"loadfrom\"]\n",
    "        with torch.no_grad():\n",
    "            layers, features, handles = install_hooks(model)\n",
    "            \n",
    "            metrics = evaluate_model(model, dl, 'acc', verbose=2, device=device)\n",
    "            params.update(metrics)\n",
    "            classes = None\n",
    "            df = perform_analysis(features, classes, layers, params, n=8000)\n",
    "            df.to_csv(f\"{outpath}\")\n",
    "                    \n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "        del model, layers, features, metrics, params, df, handles\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2928d3-9c5f-411f-a590-14fd04026ab6",
   "metadata": {},
   "source": [
    "# Stitch at a given layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbaf773-ed43-4d91-b0a0-a35fd468ac02",
   "metadata": {},
   "source": [
    "## Train the stitch layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1c72bd-a3d0-471d-809c-06e6d532d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    layer_to_cut_after = 1\n",
    "    device = \"cpu\"\n",
    "    model = torchvision.models.vgg19(weights=None, num_classes=10).to(device)  # Untrained model\n",
    "    #model.load_state_dict(torch.load(filename, map_location=torch.device(device)))  # uses either the load/save name depending whether it'\n",
    "    cut_layer_output_size = get_layer_output_shape(model, layer_to_cut_after, vgg19_input_shape, device, type=\"VGG19\")\n",
    "    model_cut = RcvVGG19(model, layer_to_cut_after, vgg19_input_shape, device).to(device)\n",
    "    print(model_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c29d808-b86e-4a0c-a3c5-127c952f3ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate ranks and output to ./results_2j_a_rank/randinit1unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "stitch from model randinit\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 1 of send_model is: torch.Size([1, 64, 32, 32])\n",
      "Train the stitch after layer 1\n",
      "Epoch 0, loss 29.24\n",
      "Epoch 1, loss 7.94\n",
      "Epoch 2, loss 6.41\n",
      "Epoch 3, loss 5.62\n",
      "Epoch 8, loss 4.65\n",
      "Epoch 9, loss 4.81\n",
      "Epoch 10, loss 4.78\n",
      "Epoch 11, loss 5.23\n",
      "Epoch 12, loss 5.27\n",
      "Epoch 13, loss 5.34\n",
      "Epoch 14, loss 5.41\n",
      "Epoch 15, loss 5.73\n",
      "Epoch 16, loss 5.72\n",
      "Epoch 17, loss 5.79\n",
      "Epoch 18, loss 5.83\n",
      "Epoch 19, loss 5.99\n",
      "Epoch 20, loss 5.91\n",
      "Epoch 21, loss 6.07\n",
      "Epoch 22, loss 6.13\n",
      "Epoch 23, loss 6.01\n",
      "Epoch 24, loss 6.07\n",
      "Epoch 25, loss 6.24\n",
      "Epoch 26, loss 6.12\n",
      "Epoch 27, loss 6.20\n",
      "Epoch 28, loss 6.12\n",
      "Epoch 29, loss 6.31\n",
      "Epoch 30, loss 6.18\n",
      "Epoch 31, loss 6.15\n",
      "Epoch 32, loss 6.31\n",
      "Epoch 33, loss 6.35\n",
      "Epoch 34, loss 6.21\n",
      "Epoch 35, loss 6.31\n",
      "Epoch 36, loss 6.21\n",
      "Epoch 37, loss 6.31\n",
      "Epoch 38, loss 6.31\n",
      "Epoch 39, loss 6.34\n",
      "Epoch 40, loss 6.46\n",
      "Epoch 41, loss 6.35\n",
      "Epoch 42, loss 6.24\n",
      "Epoch 43, loss 6.28\n",
      "Epoch 44, loss 6.27\n",
      "Epoch 45, loss 6.22\n",
      "Epoch 46, loss 6.32\n",
      "Epoch 47, loss 6.44\n",
      "Epoch 48, loss 6.32\n",
      "Epoch 49, loss 6.36\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 64\n",
      "Change in stitch weights: 4.6021013259887695\n",
      "Largest abs weight change: 0.1611872911453247\n",
      "Number of weights changing > 0.1 of that: 3544\n",
      "Change in stitch bias: 0.5811596512794495\n",
      "Largest abs bias change: 0.1232379898428917\n",
      "Number of bias changing > 0.1 of that: 58\n",
      "Test the trained stitch\n",
      "Test Accuracy: 98.38 %\n",
      "Confusion Matrix\n",
      "tensor([[ 973,    0,    0,    0,    0,    0,    2,    1,    3,    1],\n",
      "        [   1, 1125,    2,    0,    1,    0,    1,    0,    5,    0],\n",
      "        [   2,    0, 1022,    0,    0,    0,    0,    4,    4,    0],\n",
      "        [   0,    0,    3,  997,    0,    3,    0,    2,    4,    1],\n",
      "        [   0,    1,    0,    0,  958,    0,    3,    2,    1,   17],\n",
      "        [   2,    1,    0,    9,    0,  872,    2,    1,    3,    2],\n",
      "        [   5,    3,    0,    1,    2,    4,  942,    0,    1,    0],\n",
      "        [   1,    3,    3,    2,    0,    0,    0, 1012,    1,    6],\n",
      "        [   2,    0,    3,    4,    1,    3,    0,    2,  954,    5],\n",
      "        [   3,    4,    0,    8,    4,    2,    0,    5,    0,  983]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/randinit1unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "Evaluate ranks and output to ./results_2j_a_rank/randinit8unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "stitch from model randinit\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 8 of send_model is: torch.Size([1, 128, 16, 16])\n",
      "Train the stitch after layer 8\n",
      "Epoch 0, loss 468.16\n",
      "Epoch 1, loss 164.65\n",
      "Epoch 2, loss 138.87\n",
      "Epoch 3, loss 127.29\n",
      "Epoch 4, loss 122.02\n",
      "Epoch 5, loss 118.98\n",
      "Epoch 6, loss 117.04\n",
      "Epoch 7, loss 116.15\n",
      "Epoch 8, loss 115.69\n",
      "Epoch 9, loss 115.15\n",
      "Epoch 10, loss 115.16\n",
      "Epoch 11, loss 115.66\n",
      "Epoch 12, loss 115.70\n",
      "Epoch 13, loss 116.27\n",
      "Epoch 14, loss 117.00\n",
      "Epoch 15, loss 117.92\n",
      "Epoch 16, loss 118.60\n",
      "Epoch 17, loss 119.21\n",
      "Epoch 18, loss 119.75\n",
      "Epoch 19, loss 120.01\n",
      "Epoch 20, loss 121.20\n",
      "Epoch 21, loss 121.56\n",
      "Epoch 22, loss 121.45\n",
      "Epoch 23, loss 122.35\n",
      "Epoch 24, loss 122.01\n",
      "Epoch 25, loss 122.32\n",
      "Epoch 26, loss 121.89\n",
      "Epoch 27, loss 122.31\n",
      "Epoch 28, loss 122.55\n",
      "Epoch 29, loss 122.34\n",
      "Epoch 30, loss 122.11\n",
      "Epoch 31, loss 121.87\n",
      "Epoch 32, loss 122.35\n",
      "Epoch 33, loss 122.04\n",
      "Epoch 34, loss 122.50\n",
      "Epoch 35, loss 122.04\n",
      "Epoch 36, loss 122.55\n",
      "Epoch 37, loss 122.20\n",
      "Epoch 38, loss 121.75\n",
      "Epoch 39, loss 122.20\n",
      "Epoch 40, loss 122.40\n",
      "Epoch 41, loss 121.82\n",
      "Epoch 42, loss 121.85\n",
      "Epoch 43, loss 122.17\n",
      "Epoch 44, loss 122.01\n",
      "Epoch 45, loss 122.01\n",
      "Epoch 46, loss 122.12\n",
      "Epoch 47, loss 121.67\n",
      "Epoch 48, loss 122.25\n",
      "Epoch 49, loss 121.84\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 128\n",
      "Change in stitch weights: 6.704222202301025\n",
      "Largest abs weight change: 0.13953524827957153\n",
      "Number of weights changing > 0.1 of that: 13779\n",
      "Change in stitch bias: 0.5787571668624878\n",
      "Largest abs bias change: 0.08726523816585541\n",
      "Number of bias changing > 0.1 of that: 111\n",
      "Test the trained stitch\n",
      "Test Accuracy: 97.93 %\n",
      "Confusion Matrix\n",
      "tensor([[ 974,    0,    0,    0,    0,    0,    3,    1,    2,    0],\n",
      "        [   0, 1127,    2,    0,    0,    1,    1,    0,    4,    0],\n",
      "        [   4,    1, 1016,    1,    0,    0,    1,    4,    5,    0],\n",
      "        [   0,    0,    4,  990,    0,    5,    0,    3,    6,    2],\n",
      "        [   0,    1,    1,    0,  957,    0,    4,    1,    1,   17],\n",
      "        [   2,    0,    0,    9,    0,  872,    6,    1,    2,    0],\n",
      "        [   5,    4,    0,    1,    3,    3,  939,    0,    3,    0],\n",
      "        [   2,    4,    7,    2,    0,    0,    0, 1001,    1,   11],\n",
      "        [   7,    0,    2,    6,    2,    4,    1,    4,  938,   10],\n",
      "        [   2,    7,    0,    8,    5,    2,    0,    6,    0,  979]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/randinit8unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "Evaluate ranks and output to ./results_2j_a_rank/randinit22unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "stitch from model randinit\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 22 of send_model is: torch.Size([1, 512, 4, 4])\n",
      "Train the stitch after layer 22\n",
      "Epoch 0, loss 620.12\n",
      "Epoch 1, loss 324.50\n",
      "Epoch 2, loss 269.23\n",
      "Epoch 3, loss 239.60\n",
      "Epoch 4, loss 220.12\n",
      "Epoch 5, loss 208.59\n",
      "Epoch 6, loss 202.89\n",
      "Epoch 7, loss 199.81\n",
      "Epoch 8, loss 196.45\n",
      "Epoch 9, loss 198.62\n",
      "Epoch 10, loss 199.04\n",
      "Epoch 11, loss 200.25\n",
      "Epoch 12, loss 201.12\n",
      "Epoch 13, loss 203.55\n",
      "Epoch 14, loss 208.10\n",
      "Epoch 15, loss 211.42\n",
      "Epoch 16, loss 210.35\n",
      "Epoch 17, loss 216.73\n",
      "Epoch 18, loss 214.41\n",
      "Epoch 19, loss 221.59\n",
      "Epoch 20, loss 223.52\n",
      "Epoch 21, loss 225.85\n",
      "Epoch 22, loss 224.67\n",
      "Epoch 23, loss 223.18\n",
      "Epoch 24, loss 226.52\n",
      "Epoch 25, loss 224.88\n",
      "Epoch 26, loss 226.72\n",
      "Epoch 27, loss 225.30\n",
      "Epoch 28, loss 227.00\n",
      "Epoch 29, loss 228.30\n",
      "Epoch 30, loss 226.72\n",
      "Epoch 31, loss 227.26\n",
      "Epoch 32, loss 227.39\n",
      "Epoch 33, loss 226.81\n",
      "Epoch 34, loss 226.32\n",
      "Epoch 35, loss 223.84\n",
      "Epoch 36, loss 224.41\n",
      "Epoch 37, loss 223.69\n",
      "Epoch 38, loss 225.10\n",
      "Epoch 39, loss 224.49\n",
      "Epoch 40, loss 221.90\n",
      "Epoch 41, loss 223.80\n",
      "Epoch 42, loss 222.34\n",
      "Epoch 43, loss 220.37\n",
      "Epoch 44, loss 222.71\n",
      "Epoch 45, loss 220.79\n",
      "Epoch 46, loss 221.66\n",
      "Epoch 47, loss 222.35\n",
      "Epoch 48, loss 220.50\n",
      "Epoch 49, loss 222.13\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 512\n",
      "Change in stitch weights: 13.391002655029297\n",
      "Largest abs weight change: 0.07202573120594025\n",
      "Number of weights changing > 0.1 of that: 219044\n",
      "Change in stitch bias: 0.5508390069007874\n",
      "Largest abs bias change: 0.04376428201794624\n",
      "Number of bias changing > 0.1 of that: 451\n",
      "Test the trained stitch\n",
      "Test Accuracy: 93.37 %\n",
      "Confusion Matrix\n",
      "tensor([[ 968,    0,    1,    3,    0,    1,    0,    1,    5,    1],\n",
      "        [   0, 1113,   10,    3,    0,    0,    1,    0,    7,    1],\n",
      "        [   7,    1,  986,   17,    2,    0,    0,    7,   12,    0],\n",
      "        [   0,    0,    6,  986,    0,    0,    0,    8,    8,    2],\n",
      "        [   2,   10,    7,    1,  857,    0,   13,    3,   12,   77],\n",
      "        [   9,    0,    3,  111,    1,  729,    6,    2,   25,    6],\n",
      "        [  25,    6,    8,    0,    5,    7,  897,    0,   10,    0],\n",
      "        [   2,    5,   22,    6,    1,    1,    0,  970,    1,   20],\n",
      "        [   6,    2,    9,   31,    2,    2,    2,    7,  903,   10],\n",
      "        [   8,    5,    1,   24,    5,    0,    1,   26,   11,  928]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/randinit22unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "Evaluate ranks and output to ./results_2j_a_rank/randinit29unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "stitch from model randinit\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 29 of send_model is: torch.Size([1, 512, 2, 2])\n",
      "Train the stitch after layer 29\n",
      "Epoch 0, loss 948.03\n",
      "Epoch 1, loss 538.03\n",
      "Epoch 2, loss 455.98\n",
      "Epoch 3, loss 410.63\n",
      "Epoch 4, loss 385.43\n",
      "Epoch 5, loss 375.42\n",
      "Epoch 6, loss 363.98\n",
      "Epoch 7, loss 358.78\n",
      "Epoch 8, loss 354.66\n",
      "Epoch 9, loss 353.97\n",
      "Epoch 10, loss 355.90\n",
      "Epoch 11, loss 358.73\n",
      "Epoch 12, loss 362.40\n",
      "Epoch 13, loss 362.24\n",
      "Epoch 14, loss 367.20\n",
      "Epoch 15, loss 370.24\n",
      "Epoch 16, loss 371.21\n",
      "Epoch 17, loss 374.56\n",
      "Epoch 18, loss 385.54\n",
      "Epoch 19, loss 385.16\n",
      "Epoch 20, loss 385.34\n",
      "Epoch 21, loss 389.11\n",
      "Epoch 22, loss 393.51\n",
      "Epoch 23, loss 391.70\n",
      "Epoch 24, loss 394.76\n",
      "Epoch 25, loss 394.58\n",
      "Epoch 26, loss 397.74\n",
      "Epoch 27, loss 400.68\n",
      "Epoch 28, loss 398.28\n",
      "Epoch 29, loss 402.27\n",
      "Epoch 30, loss 399.71\n",
      "Epoch 31, loss 401.62\n",
      "Epoch 32, loss 399.50\n",
      "Epoch 33, loss 399.15\n",
      "Epoch 34, loss 403.23\n",
      "Epoch 35, loss 396.61\n",
      "Epoch 36, loss 403.83\n",
      "Epoch 37, loss 403.12\n",
      "Epoch 38, loss 405.29\n",
      "Epoch 39, loss 402.16\n",
      "Epoch 40, loss 400.97\n",
      "Epoch 41, loss 400.43\n",
      "Epoch 42, loss 400.43\n",
      "Epoch 43, loss 401.17\n",
      "Epoch 44, loss 400.31\n",
      "Epoch 45, loss 403.20\n",
      "Epoch 46, loss 399.69\n",
      "Epoch 47, loss 399.76\n",
      "Epoch 48, loss 407.24\n",
      "Epoch 49, loss 397.62\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 512\n",
      "Change in stitch weights: 13.550786018371582\n",
      "Largest abs weight change: 0.0763920396566391\n",
      "Number of weights changing > 0.1 of that: 216787\n",
      "Change in stitch bias: 0.5962435603141785\n",
      "Largest abs bias change: 0.04378071427345276\n",
      "Number of bias changing > 0.1 of that: 473\n",
      "Test the trained stitch\n",
      "Test Accuracy: 90.52 %\n",
      "Confusion Matrix\n",
      "tensor([[ 943,    0,    1,    6,    1,   14,    9,    1,    4,    1],\n",
      "        [   0, 1109,    5,    3,    0,    1,    5,    0,   11,    1],\n",
      "        [  22,    7,  894,   31,   10,    3,   18,   14,   32,    1],\n",
      "        [   3,    5,   13,  911,    2,   44,    2,   11,   14,    5],\n",
      "        [   3,    6,    1,    0,  858,   10,   36,    0,    7,   61],\n",
      "        [   7,    3,    2,   52,    2,  779,   20,    5,   16,    6],\n",
      "        [  15,    8,    0,    0,    8,   15,  905,    1,    6,    0],\n",
      "        [   3,   15,   23,    6,    6,    4,    1,  927,    4,   39],\n",
      "        [  11,    4,    6,   36,    8,   41,    9,    7,  835,   17],\n",
      "        [  12,   10,    1,   13,   37,   12,    0,   21,   12,  891]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/randinit29unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "Evaluate ranks and output to ./results_2j_a_rank/randinit35unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "stitch from model randinit\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 35 of send_model is: torch.Size([1, 512, 2, 2])\n",
      "Train the stitch after layer 35\n",
      "Epoch 0, loss 958.38\n",
      "Epoch 1, loss 625.55\n",
      "Epoch 2, loss 550.73\n",
      "Epoch 3, loss 511.04\n",
      "Epoch 4, loss 483.79\n",
      "Epoch 5, loss 468.47\n",
      "Epoch 6, loss 454.10\n",
      "Epoch 7, loss 441.39\n",
      "Epoch 8, loss 437.02\n",
      "Epoch 9, loss 428.80\n",
      "Epoch 10, loss 426.62\n",
      "Epoch 11, loss 422.65\n",
      "Epoch 12, loss 421.75\n",
      "Epoch 13, loss 421.36\n",
      "Epoch 14, loss 424.06\n",
      "Epoch 15, loss 421.75\n",
      "Epoch 16, loss 422.99\n",
      "Epoch 17, loss 422.90\n",
      "Epoch 18, loss 420.96\n",
      "Epoch 19, loss 420.75\n",
      "Epoch 20, loss 422.75\n",
      "Epoch 21, loss 420.37\n",
      "Epoch 22, loss 421.60\n",
      "Epoch 23, loss 420.36\n",
      "Epoch 24, loss 419.92\n",
      "Epoch 25, loss 421.33\n",
      "Epoch 26, loss 419.76\n",
      "Epoch 27, loss 419.89\n",
      "Epoch 28, loss 418.69\n",
      "Epoch 29, loss 416.13\n",
      "Epoch 30, loss 414.25\n",
      "Epoch 31, loss 415.88\n",
      "Epoch 32, loss 419.20\n",
      "Epoch 33, loss 416.37\n",
      "Epoch 34, loss 412.88\n",
      "Epoch 35, loss 412.63\n",
      "Epoch 36, loss 411.82\n",
      "Epoch 37, loss 412.03\n",
      "Epoch 38, loss 409.92\n",
      "Epoch 39, loss 412.03\n",
      "Epoch 40, loss 413.72\n",
      "Epoch 41, loss 410.26\n",
      "Epoch 42, loss 410.56\n",
      "Epoch 43, loss 411.96\n",
      "Epoch 44, loss 409.67\n",
      "Epoch 45, loss 407.21\n",
      "Epoch 46, loss 410.08\n",
      "Epoch 47, loss 409.00\n",
      "Epoch 48, loss 410.70\n",
      "Epoch 49, loss 409.55\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 512\n",
      "Change in stitch weights: 13.535089492797852\n",
      "Largest abs weight change: 0.10355418920516968\n",
      "Number of weights changing > 0.1 of that: 199973\n",
      "Change in stitch bias: 0.5739171504974365\n",
      "Largest abs bias change: 0.04372432082891464\n",
      "Number of bias changing > 0.1 of that: 453\n",
      "Test the trained stitch\n",
      "Test Accuracy: 89.37 %\n",
      "Confusion Matrix\n",
      "tensor([[ 947,    1,    4,    3,    0,    9,    5,    1,    8,    2],\n",
      "        [   0, 1113,    9,    2,    0,    0,    3,    0,    7,    1],\n",
      "        [  18,   10,  934,   14,   10,    1,   15,   14,   16,    0],\n",
      "        [   6,    9,   30,  897,    1,   24,    2,   11,   16,   14],\n",
      "        [   2,   10,    5,    1,  843,    5,   27,    4,   10,   75],\n",
      "        [  13,    8,    5,   67,    9,  731,   21,    8,   20,   10],\n",
      "        [  19,    8,    6,    0,   14,   18,  886,    0,    7,    0],\n",
      "        [   3,   16,   30,    5,    9,    2,    1,  897,    7,   58],\n",
      "        [  13,   13,   22,   36,    6,   20,   12,    8,  822,   22],\n",
      "        [  11,   16,    4,   14,   51,    6,    0,   24,   16,  867]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/randinit35unbias-unbias-107_2025-03-26_18-57-22_SEED107_EPOCHS50_BGN0.1_exp2h_VGG19_randinit-test.csv\n",
      "Evaluate ranks and output to ./results_2j_a_rank/unbias1unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "stitch from model unbias\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 1 of send_model is: torch.Size([1, 64, 32, 32])\n",
      "Train the stitch after layer 1\n",
      "Epoch 0, loss 36.79\n",
      "Epoch 1, loss 9.63\n",
      "Epoch 2, loss 7.61\n",
      "Epoch 3, loss 5.88\n",
      "Epoch 4, loss 4.84\n",
      "Epoch 5, loss 5.06\n",
      "Epoch 6, loss 4.24\n",
      "Epoch 7, loss 4.45\n",
      "Epoch 8, loss 4.58\n",
      "Epoch 9, loss 4.51\n",
      "Epoch 10, loss 4.73\n",
      "Epoch 11, loss 5.12\n",
      "Epoch 12, loss 5.17\n",
      "Epoch 13, loss 5.22\n",
      "Epoch 14, loss 5.41\n",
      "Epoch 15, loss 5.54\n",
      "Epoch 16, loss 5.80\n",
      "Epoch 17, loss 5.74\n",
      "Epoch 18, loss 5.79\n",
      "Epoch 19, loss 6.10\n",
      "Epoch 20, loss 5.99\n",
      "Epoch 21, loss 6.00\n",
      "Epoch 22, loss 6.15\n",
      "Epoch 23, loss 5.92\n",
      "Epoch 24, loss 6.11\n",
      "Epoch 25, loss 6.13\n",
      "Epoch 26, loss 6.03\n",
      "Epoch 27, loss 6.05\n",
      "Epoch 28, loss 6.17\n",
      "Epoch 29, loss 6.37\n",
      "Epoch 30, loss 6.28\n",
      "Epoch 31, loss 6.12\n",
      "Epoch 32, loss 6.16\n",
      "Epoch 33, loss 6.31\n",
      "Epoch 34, loss 6.18\n",
      "Epoch 35, loss 6.31\n",
      "Epoch 36, loss 6.31\n",
      "Epoch 37, loss 6.39\n",
      "Epoch 38, loss 6.11\n",
      "Epoch 39, loss 6.32\n",
      "Epoch 40, loss 6.19\n",
      "Epoch 41, loss 6.12\n",
      "Epoch 42, loss 6.37\n",
      "Epoch 43, loss 6.10\n",
      "Epoch 44, loss 6.20\n",
      "Epoch 45, loss 6.27\n",
      "Epoch 46, loss 6.31\n",
      "Epoch 47, loss 6.21\n",
      "Epoch 48, loss 6.19\n",
      "Epoch 49, loss 6.15\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 64\n",
      "Change in stitch weights: 4.641698837280273\n",
      "Largest abs weight change: 0.14046749472618103\n",
      "Number of weights changing > 0.1 of that: 3647\n",
      "Change in stitch bias: 0.5079816579818726\n",
      "Largest abs bias change: 0.11259667575359344\n",
      "Number of bias changing > 0.1 of that: 55\n",
      "Test the trained stitch\n",
      "Test Accuracy: 98.41 %\n",
      "Confusion Matrix\n",
      "tensor([[ 975,    0,    0,    0,    0,    0,    2,    1,    1,    1],\n",
      "        [   0, 1125,    2,    0,    2,    0,    1,    0,    5,    0],\n",
      "        [   2,    0, 1022,    0,    0,    0,    0,    4,    4,    0],\n",
      "        [   0,    0,    3,  996,    0,    4,    0,    2,    4,    1],\n",
      "        [   0,    0,    2,    0,  959,    0,    2,    1,    1,   17],\n",
      "        [   2,    1,    0,    9,    0,  872,    2,    1,    2,    3],\n",
      "        [   5,    3,    0,    1,    2,    3,  942,    0,    2,    0],\n",
      "        [   1,    3,    2,    2,    0,    0,    0, 1013,    1,    6],\n",
      "        [   2,    0,    3,    5,    1,    3,    0,    3,  952,    5],\n",
      "        [   3,    4,    0,    6,    4,    2,    0,    5,    0,  985]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/unbias1unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "Evaluate ranks and output to ./results_2j_a_rank/unbias8unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "stitch from model unbias\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 8 of send_model is: torch.Size([1, 128, 16, 16])\n",
      "Train the stitch after layer 8\n",
      "Epoch 0, loss 231.15\n",
      "Epoch 1, loss 108.39\n",
      "Epoch 2, loss 97.45\n",
      "Epoch 3, loss 94.31\n",
      "Epoch 4, loss 93.17\n",
      "Epoch 5, loss 92.94\n",
      "Epoch 6, loss 93.88\n",
      "Epoch 7, loss 94.46\n",
      "Epoch 8, loss 95.42\n",
      "Epoch 9, loss 95.90\n",
      "Epoch 10, loss 96.41\n",
      "Epoch 11, loss 97.23\n",
      "Epoch 12, loss 98.04\n",
      "Epoch 13, loss 97.83\n",
      "Epoch 14, loss 98.00\n",
      "Epoch 15, loss 99.05\n",
      "Epoch 16, loss 99.65\n",
      "Epoch 17, loss 99.65\n",
      "Epoch 18, loss 99.71\n",
      "Epoch 19, loss 100.18\n",
      "Epoch 20, loss 100.85\n",
      "Epoch 21, loss 100.70\n",
      "Epoch 22, loss 101.14\n",
      "Epoch 23, loss 101.10\n",
      "Epoch 24, loss 100.53\n",
      "Epoch 25, loss 101.23\n",
      "Epoch 26, loss 101.01\n",
      "Epoch 27, loss 101.28\n",
      "Epoch 28, loss 100.90\n",
      "Epoch 29, loss 100.62\n",
      "Epoch 30, loss 101.15\n",
      "Epoch 31, loss 100.76\n",
      "Epoch 32, loss 100.80\n",
      "Epoch 33, loss 101.24\n",
      "Epoch 34, loss 100.85\n",
      "Epoch 35, loss 101.07\n",
      "Epoch 36, loss 100.94\n",
      "Epoch 37, loss 100.60\n",
      "Epoch 38, loss 100.94\n",
      "Epoch 39, loss 100.92\n",
      "Epoch 40, loss 101.04\n",
      "Epoch 41, loss 100.96\n",
      "Epoch 42, loss 101.13\n",
      "Epoch 43, loss 100.67\n",
      "Epoch 44, loss 100.57\n",
      "Epoch 45, loss 100.72\n",
      "Epoch 46, loss 100.51\n",
      "Epoch 47, loss 100.95\n",
      "Epoch 48, loss 100.62\n",
      "Epoch 49, loss 100.54\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 128\n",
      "Change in stitch weights: 6.654745101928711\n",
      "Largest abs weight change: 0.1337224245071411\n",
      "Number of weights changing > 0.1 of that: 13883\n",
      "Change in stitch bias: 0.5644828677177429\n",
      "Largest abs bias change: 0.0873362347483635\n",
      "Number of bias changing > 0.1 of that: 117\n",
      "Test the trained stitch\n",
      "Test Accuracy: 98.29 %\n",
      "Confusion Matrix\n",
      "tensor([[ 974,    0,    0,    0,    0,    1,    3,    1,    1,    0],\n",
      "        [   0, 1127,    2,    0,    0,    1,    1,    1,    3,    0],\n",
      "        [   5,    1, 1021,    1,    0,    0,    0,    3,    1,    0],\n",
      "        [   0,    0,    5,  992,    0,    6,    0,    2,    4,    1],\n",
      "        [   0,    0,    1,    0,  962,    0,    5,    1,    0,   13],\n",
      "        [   2,    1,    0,    7,    0,  874,    4,    1,    2,    1],\n",
      "        [   3,    3,    0,    1,    2,    4,  943,    0,    2,    0],\n",
      "        [   2,    2,    4,    1,    0,    0,    0, 1014,    1,    4],\n",
      "        [   3,    0,    4,    3,    2,    5,    1,    4,  946,    6],\n",
      "        [   2,    8,    0,    9,    8,    0,    0,    6,    0,  976]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/unbias8unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "Evaluate ranks and output to ./results_2j_a_rank/unbias22unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "stitch from model unbias\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 22 of send_model is: torch.Size([1, 512, 4, 4])\n",
      "Train the stitch after layer 22\n",
      "Epoch 0, loss 186.99\n",
      "Epoch 1, loss 86.52\n",
      "Epoch 2, loss 71.27\n",
      "Epoch 3, loss 62.41\n",
      "Epoch 4, loss 57.83\n",
      "Epoch 5, loss 54.89\n",
      "Epoch 6, loss 53.31\n",
      "Epoch 7, loss 52.62\n",
      "Epoch 8, loss 52.66\n",
      "Epoch 9, loss 52.73\n",
      "Epoch 10, loss 53.27\n",
      "Epoch 11, loss 54.51\n",
      "Epoch 12, loss 55.80\n",
      "Epoch 13, loss 56.65\n",
      "Epoch 14, loss 58.36\n",
      "Epoch 15, loss 59.47\n",
      "Epoch 16, loss 60.80\n",
      "Epoch 17, loss 62.83\n",
      "Epoch 18, loss 64.60\n",
      "Epoch 19, loss 66.10\n",
      "Epoch 20, loss 66.99\n",
      "Epoch 21, loss 68.90\n",
      "Epoch 22, loss 69.92\n",
      "Epoch 23, loss 71.24\n",
      "Epoch 24, loss 72.81\n",
      "Epoch 25, loss 73.47\n",
      "Epoch 26, loss 74.40\n",
      "Epoch 27, loss 74.38\n",
      "Epoch 28, loss 74.97\n",
      "Epoch 29, loss 75.40\n",
      "Epoch 30, loss 75.32\n",
      "Epoch 31, loss 75.18\n",
      "Epoch 32, loss 75.39\n",
      "Epoch 33, loss 76.08\n",
      "Epoch 34, loss 75.31\n",
      "Epoch 35, loss 75.19\n",
      "Epoch 36, loss 75.56\n",
      "Epoch 37, loss 75.46\n",
      "Epoch 38, loss 74.79\n",
      "Epoch 39, loss 75.04\n",
      "Epoch 40, loss 75.22\n",
      "Epoch 41, loss 74.50\n",
      "Epoch 42, loss 75.09\n",
      "Epoch 43, loss 75.10\n",
      "Epoch 44, loss 74.82\n",
      "Epoch 45, loss 74.60\n",
      "Epoch 46, loss 74.67\n",
      "Epoch 47, loss 75.19\n",
      "Epoch 48, loss 74.68\n",
      "Epoch 49, loss 74.58\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 512\n",
      "Change in stitch weights: 13.188955307006836\n",
      "Largest abs weight change: 0.060193102806806564\n",
      "Number of weights changing > 0.1 of that: 226445\n",
      "Change in stitch bias: 0.5827369093894958\n",
      "Largest abs bias change: 0.043732475489377975\n",
      "Number of bias changing > 0.1 of that: 463\n",
      "Test the trained stitch\n",
      "Test Accuracy: 98.21 %\n",
      "Confusion Matrix\n",
      "tensor([[ 971,    0,    0,    0,    0,    2,    3,    1,    3,    0],\n",
      "        [   0, 1120,    2,    0,    0,    1,    3,    0,    9,    0],\n",
      "        [   5,    2, 1015,    4,    0,    0,    1,    1,    4,    0],\n",
      "        [   0,    0,    3,  997,    0,    2,    0,    3,    4,    1],\n",
      "        [   0,    1,    0,    0,  960,    0,    5,    1,    0,   15],\n",
      "        [   2,    0,    0,    8,    0,  878,    2,    1,    1,    0],\n",
      "        [   3,    2,    0,    0,    3,    4,  944,    0,    2,    0],\n",
      "        [   1,    4,    7,    3,    0,    0,    0, 1009,    1,    3],\n",
      "        [   4,    0,    1,    5,    1,    5,    0,    2,  954,    2],\n",
      "        [   2,    5,    0,   12,    5,    5,    1,    3,    3,  973]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/unbias22unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "Evaluate ranks and output to ./results_2j_a_rank/unbias29unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "stitch from model unbias\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 29 of send_model is: torch.Size([1, 512, 2, 2])\n",
      "Train the stitch after layer 29\n",
      "Epoch 0, loss 151.76\n",
      "Epoch 1, loss 45.77\n",
      "Epoch 2, loss 35.33\n",
      "Epoch 3, loss 31.19\n",
      "Epoch 4, loss 29.58\n",
      "Epoch 5, loss 28.57\n",
      "Epoch 6, loss 28.86\n",
      "Epoch 7, loss 29.90\n",
      "Epoch 8, loss 31.22\n",
      "Epoch 9, loss 32.85\n",
      "Epoch 10, loss 34.98\n",
      "Epoch 11, loss 38.60\n",
      "Epoch 12, loss 41.45\n",
      "Epoch 13, loss 45.09\n",
      "Epoch 14, loss 48.90\n",
      "Epoch 15, loss 52.45\n",
      "Epoch 16, loss 55.63\n",
      "Epoch 17, loss 58.64\n",
      "Epoch 18, loss 60.89\n",
      "Epoch 19, loss 63.08\n",
      "Epoch 20, loss 64.68\n",
      "Epoch 21, loss 66.39\n",
      "Epoch 22, loss 67.46\n",
      "Epoch 23, loss 69.11\n",
      "Epoch 24, loss 69.97\n",
      "Epoch 25, loss 70.48\n",
      "Epoch 26, loss 71.24\n",
      "Epoch 27, loss 71.60\n",
      "Epoch 28, loss 71.80\n",
      "Epoch 29, loss 72.21\n",
      "Epoch 30, loss 72.58\n",
      "Epoch 31, loss 72.57\n",
      "Epoch 32, loss 72.87\n",
      "Epoch 33, loss 72.62\n",
      "Epoch 34, loss 72.75\n",
      "Epoch 35, loss 72.83\n",
      "Epoch 36, loss 72.54\n",
      "Epoch 37, loss 73.05\n",
      "Epoch 38, loss 72.84\n",
      "Epoch 39, loss 72.61\n",
      "Epoch 40, loss 72.64\n",
      "Epoch 41, loss 72.75\n",
      "Epoch 42, loss 72.85\n",
      "Epoch 43, loss 72.96\n",
      "Epoch 44, loss 72.48\n",
      "Epoch 45, loss 72.73\n",
      "Epoch 46, loss 72.77\n",
      "Epoch 47, loss 72.80\n",
      "Epoch 48, loss 72.74\n",
      "Epoch 49, loss 72.66\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 512\n",
      "Change in stitch weights: 13.136719703674316\n",
      "Largest abs weight change: 0.06270590424537659\n",
      "Number of weights changing > 0.1 of that: 224934\n",
      "Change in stitch bias: 0.5813040733337402\n",
      "Largest abs bias change: 0.04376683384180069\n",
      "Number of bias changing > 0.1 of that: 467\n",
      "Test the trained stitch\n",
      "Test Accuracy: 98.48 %\n",
      "Confusion Matrix\n",
      "tensor([[ 973,    0,    0,    0,    0,    0,    4,    1,    2,    0],\n",
      "        [   0, 1126,    2,    0,    1,    0,    2,    0,    4,    0],\n",
      "        [   3,    0, 1023,    1,    0,    0,    0,    1,    4,    0],\n",
      "        [   0,    0,    4,  994,    0,    4,    0,    3,    3,    2],\n",
      "        [   0,    0,    0,    0,  961,    0,    5,    1,    1,   14],\n",
      "        [   2,    1,    0,    7,    0,  876,    3,    1,    2,    0],\n",
      "        [   4,    3,    0,    0,    3,    2,  944,    0,    2,    0],\n",
      "        [   1,    3,    6,    2,    0,    0,    0, 1009,    1,    6],\n",
      "        [   2,    0,    2,    1,    1,    4,    0,    4,  956,    4],\n",
      "        [   2,    4,    0,    6,    5,    1,    1,    4,    0,  986]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/unbias29unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "Evaluate ranks and output to ./results_2j_a_rank/unbias35unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n",
      "stitch from model unbias\n",
      "get_layer_output_shape for type='VGG19'\n",
      "The shape of the output from layer 35 of send_model is: torch.Size([1, 512, 2, 2])\n",
      "Train the stitch after layer 35\n",
      "Epoch 0, loss 41.05\n",
      "Epoch 1, loss 11.75\n",
      "Epoch 2, loss 10.08\n",
      "Epoch 3, loss 9.12\n",
      "Epoch 4, loss 8.99\n",
      "Epoch 5, loss 8.71\n",
      "Epoch 6, loss 8.99\n",
      "Epoch 7, loss 9.32\n",
      "Epoch 8, loss 9.68\n",
      "Epoch 9, loss 10.11\n",
      "Epoch 10, loss 11.26\n",
      "Epoch 11, loss 12.25\n",
      "Epoch 12, loss 13.82\n",
      "Epoch 13, loss 15.59\n",
      "Epoch 14, loss 17.78\n",
      "Epoch 15, loss 20.25\n",
      "Epoch 16, loss 23.02\n",
      "Epoch 17, loss 25.52\n",
      "Epoch 18, loss 28.19\n",
      "Epoch 19, loss 30.40\n",
      "Epoch 20, loss 33.00\n",
      "Epoch 21, loss 34.23\n",
      "Epoch 22, loss 35.89\n",
      "Epoch 23, loss 36.64\n",
      "Epoch 24, loss 37.52\n",
      "Epoch 25, loss 38.68\n",
      "Epoch 26, loss 39.26\n",
      "Epoch 27, loss 39.75\n",
      "Epoch 28, loss 40.05\n",
      "Epoch 29, loss 40.00\n",
      "Epoch 30, loss 40.39\n",
      "Epoch 31, loss 40.31\n",
      "Epoch 32, loss 40.64\n",
      "Epoch 33, loss 40.58\n",
      "Epoch 34, loss 40.57\n",
      "Epoch 35, loss 40.43\n",
      "Epoch 36, loss 40.60\n",
      "Epoch 37, loss 40.76\n",
      "Epoch 38, loss 40.89\n",
      "Epoch 39, loss 40.70\n",
      "Epoch 40, loss 41.10\n",
      "Epoch 41, loss 40.71\n",
      "Epoch 42, loss 40.95\n",
      "Epoch 43, loss 40.97\n",
      "Epoch 44, loss 41.12\n",
      "Epoch 45, loss 40.60\n",
      "Epoch 46, loss 40.89\n",
      "Epoch 47, loss 40.59\n",
      "Epoch 48, loss 41.12\n",
      "Epoch 49, loss 40.61\n",
      "**** Finished Training ****\n",
      "Number of weight / bias in stitch layer is 512\n",
      "Change in stitch weights: 13.04896354675293\n",
      "Largest abs weight change: 0.06711113452911377\n",
      "Number of weights changing > 0.1 of that: 222210\n",
      "Change in stitch bias: 0.5845987200737\n",
      "Largest abs bias change: 0.04372510686516762\n",
      "Number of bias changing > 0.1 of that: 462\n",
      "Test the trained stitch\n",
      "Test Accuracy: 98.47 %\n",
      "Confusion Matrix\n",
      "tensor([[ 973,    0,    0,    0,    0,    0,    4,    1,    2,    0],\n",
      "        [   0, 1126,    2,    0,    1,    0,    2,    0,    4,    0],\n",
      "        [   4,    1, 1020,    0,    0,    0,    0,    3,    4,    0],\n",
      "        [   0,    0,    4,  993,    0,    4,    0,    4,    4,    1],\n",
      "        [   0,    1,    0,    0,  963,    0,    4,    1,    1,   12],\n",
      "        [   2,    1,    0,    6,    0,  878,    3,    1,    1,    0],\n",
      "        [   3,    3,    0,    0,    2,    4,  945,    0,    1,    0],\n",
      "        [   2,    3,    3,    1,    0,    0,    0, 1013,    1,    5],\n",
      "        [   2,    0,    2,    1,    1,    3,    0,    2,  959,    4],\n",
      "        [   3,    5,    0,    9,    4,    4,    0,    6,    1,  977]],\n",
      "       dtype=torch.int32)\n",
      "===================================================================\n",
      "output to ./results_2j_a_rank/unbias35unbias-unbias-107_2025-01-07_10-01-18_SEED107_EPOCHS50_BGN0.1_exp1g_VGG19_unbiased_colour_mnist-test.csv\n"
     ]
    }
   ],
   "source": [
    "stitching_accuracies = dict()\n",
    "stitching_penalties = dict()\n",
    "\n",
    "for key, val in process_structure.items():        \n",
    "    stitching_accuracies[key] = dict()\n",
    "    stitching_penalties[key] = dict()\n",
    "    for layer_to_cut_after in [1,8,22,29,35]:  #  [1,3,6,8,11,13,15,17,20,22,24,26,29,31,33,35]\n",
    "        ###################### Don't bother to stitch and train if we've already analysed it\n",
    "        \n",
    "        if val[\"train\"]:\n",
    "            filename = val[\"saveas\"] \n",
    "        else:    \n",
    "            filename = val[\"loadfrom\"] \n",
    "        rank_filename = filename.split('/')[-1].replace('.weights', '-test.csv')        \n",
    "        # denote output name as <model_training_type>-dataset-<name>\n",
    "        # where <model_training_type> is [sender_model or X][layer_to_cut_after][Receiver_model]\n",
    "        model_training_type = f\"{key}{layer_to_cut_after}unbias\"\n",
    "        dataset_type = \"unbias\"\n",
    "        \n",
    "        outpath = f\"./{results_root}_rank/{model_training_type}-{dataset_type}-{seed}_{rank_filename}\" \n",
    "        #PENGUIN\n",
    "                        \n",
    "        if os.path.exists(f\"{outpath}\"):\n",
    "            logtofile(f\"Already evaluated for {outpath}\")\n",
    "            continue\n",
    "        ####################################################################################\n",
    "        logtofile(f\"Evaluate ranks and output to {outpath}\")\n",
    "        logtofile(f\"stitch from model {key}\")\n",
    "                \n",
    "#        model = torchvision.models.vgg19(weights=None, num_classes=10).to(device)  # Untrained model\n",
    "#        model.load_state_dict(torch.load(filename, map_location=torch.device(device)))  # uses either the load/save name depending whether it'\n",
    "#        cut_layer_output_size = get_layer_output_shape(model, layer_to_cut_after, vgg19_input_shape, device, type=\"VGG19\")\n",
    "#        model_cut = RcvVGG19(model, layer_to_cut_after, vgg19_input_shape, device).to(device)\n",
    "\n",
    "        # Always use the standard model as receiver\n",
    "        rcv_model = torchvision.models.vgg19(weights=None, num_classes=10).to(device)  # Untrained model\n",
    "        rcv_model.load_state_dict(torch.load(unbiased_colour_mnist_model_to_load, map_location=torch.device(device)))\n",
    "        rcv_model.eval()\n",
    "        \n",
    "        # train a stitch on the unbiased_colour dataset to compare receiver network performance with stitched\n",
    "        model_stitched = StitchedVGG19(send_model=val[\"model\"], \n",
    "                                          after_layer_index=layer_to_cut_after, \n",
    "                                          rcv_model=rcv_model,\n",
    "                                          input_image_shape=vgg19_input_shape, device=device  ).to(device)\n",
    "\n",
    "        #############################################################\n",
    "        # store the initial stitch state\n",
    "        initial_stitch_weight = model_stitched.stitch.s_conv1.weight.clone()\n",
    "        initial_stitch_bias   = model_stitched.stitch.s_conv1.bias.clone()\n",
    "        stitch_initial_weight_outpath    = f\"./{results_root}/STITCH_initial_weight_{model_training_type}-{dataset_type}-{seed}_{filename.split('/')[-1]}\"  \n",
    "        stitch_initial_bias_outpath      = f\"./{results_root}/STITCH_initial_bias_{model_training_type}-{dataset_type}-{seed}_{filename.split('/')[-1]}\"  \n",
    "        if save_stitch_delta:\n",
    "            torch.save(initial_stitch_weight, stitch_initial_weight_outpath)\n",
    "            torch.save(initial_stitch_bias, stitch_initial_bias_outpath)\n",
    "        ############################################################\n",
    "                \n",
    "        # define the loss function and the optimiser\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimiser = optim.SGD(model_stitched.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.01)\n",
    "        \n",
    "        # Put top model into train mode so that bn and dropout perform in training mode\n",
    "        model_stitched.train()\n",
    "        # Freeze the top model\n",
    "        model_stitched.requires_grad_(False)\n",
    "        # Un-Freeze the stitch layer\n",
    "        for name, param in model_stitched.stitch.named_parameters():\n",
    "            param.requires_grad_(True)\n",
    "        logtofile(f\"Train the stitch after layer {layer_to_cut_after}\")    \n",
    "        # the epoch loop: note that we're training the whole network\n",
    "        \n",
    "        for epoch in range(stitch_train_epochs):\n",
    "            running_loss = 0.0\n",
    "            for data in process_structure[dataset_type][\"train_loader\"]:  \n",
    "                # data is (representations, labels) tuple\n",
    "                # get the inputs and put them on the GPU\n",
    "                inputs, labels = data\n",
    "                                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "        \n",
    "                # zero the parameter gradients\n",
    "                optimiser.zero_grad()\n",
    "        \n",
    "                # forward + loss + backward + optimise (update weights)\n",
    "                outputs = model_stitched(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimiser.step()\n",
    "        \n",
    "                # keep track of the loss this epoch\n",
    "                running_loss += loss.item()\n",
    "            logtofile(\"Epoch %d, loss %4.2f\" % (epoch, running_loss))\n",
    "        logtofile('**** Finished Training ****')\n",
    "        \n",
    "        model_stitched.eval() # ALWAYS DO THIS BEFORE YOU EVALUATE MODELS\n",
    "\n",
    "        ############################################################\n",
    "        # store the trained stitch\n",
    "        trained_stitch_weight = model_stitched.stitch.s_conv1.weight.clone()\n",
    "        trained_stitch_bias   = model_stitched.stitch.s_conv1.bias.clone()\n",
    "        stitch_trained_weight_outpath    = f\"./{results_root}/STITCH_trained_weight_{model_training_type}-{dataset_type}-{seed}_{filename.split('/')[-1]}\"  \n",
    "        stitch_trained_bias_outpath      = f\"./{results_root}/STITCH_trained_bias_{model_training_type}-{dataset_type}-{seed}_{filename.split('/')[-1]}\"  \n",
    "\n",
    "        if save_stitch_delta:\n",
    "            torch.save(trained_stitch_weight, stitch_trained_weight_outpath)\n",
    "            torch.save(trained_stitch_bias, stitch_trained_bias_outpath)\n",
    "        \n",
    "        print(f\"Number of weight / bias in stitch layer is {len(initial_stitch_weight)}\")\n",
    "        stitch_weight_diff = trained_stitch_weight - initial_stitch_weight\n",
    "        stitch_weight_delta = torch.linalg.norm(stitch_weight_diff).item()\n",
    "        logtofile(f\"Change in stitch weights: {stitch_weight_delta}\")\n",
    "        maxabsweight =  torch.max(stitch_weight_diff.abs()).item()\n",
    "        logtofile(f\"Largest abs weight change: {maxabsweight}\")\n",
    "        stitch_weight_number = torch.sum(torch.where(stitch_weight_diff.abs() > 0.1*maxabsweight, True, False)).item()\n",
    "        logtofile(f\"Number of weights changing > 0.1 of that: {stitch_weight_number}\")\n",
    "        \n",
    "        stitch_bias_diff = trained_stitch_bias - initial_stitch_bias\n",
    "        stitch_bias_delta = torch.linalg.norm(stitch_bias_diff).item()\n",
    "        logtofile(f\"Change in stitch bias: {stitch_bias_delta}\")\n",
    "        maxabsbias =  torch.max(stitch_bias_diff.abs()).item()\n",
    "        logtofile(f\"Largest abs bias change: {maxabsbias}\")\n",
    "        stitch_bias_number = torch.sum(torch.where(stitch_bias_diff.abs() > 0.1*maxabsbias, True, False)).item()\n",
    "        logtofile(f\"Number of bias changing > 0.1 of that: {stitch_bias_number}\")\n",
    "\n",
    "        #new_tensor = torch.load(\"foo_1_state.pt\")\n",
    "        ##############################################################\n",
    "        \n",
    "        logtofile(\"Test the trained stitch\")        \n",
    "        # Compute the model accuracy on the test set\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # assuming 10 classes\n",
    "        # rows represent actual class, columns are predicted\n",
    "        confusion_matrix = torch.zeros(10,10, dtype=torch.int)\n",
    "        TDL = process_structure[dataset_type][\"test_loader\"]\n",
    "        for data in TDL:\n",
    "            inputs, labels = data\n",
    "            #print(inputs)   \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            predictions = torch.argmax(model_stitched(inputs),1)\n",
    "            #print(model_cut(inputs))\n",
    "            matches = predictions == labels.to(device)\n",
    "            correct += matches.sum().item()\n",
    "            total += len(labels)\n",
    "        \n",
    "            for idx, l in enumerate(labels):\n",
    "                confusion_matrix[l, predictions[idx]] = 1 + confusion_matrix[l, predictions[idx]] \n",
    "        acc = ((100.0 * correct) / total)\n",
    "        logtofile('Test Accuracy: %2.2f %%' % acc)\n",
    "        logtofile('Confusion Matrix')\n",
    "        logtofile(confusion_matrix)\n",
    "        logtofile(\"===================================================================\")\n",
    "        stitching_accuracies[key][layer_to_cut_after] = acc\n",
    "        stitching_penalties[key][layer_to_cut_after] = original_accuracy[key] - acc        \n",
    "\n",
    "        if measure_rank:\n",
    "            dl = TDL        \n",
    "            params = {}\n",
    "            params[\"model\"] = model_training_type\n",
    "            params[\"dataset\"] = dataset_type\n",
    "            params[\"seed\"] = seed\n",
    "            if val[\"train\"]: # as only one network used, record its filename as both send and receive files\n",
    "                params[\"send_file\"] = val[\"saveas\"] \n",
    "                params[\"rcv_file\"] = val[\"saveas\"] \n",
    "            else:    \n",
    "                params[\"send_file\"] = val[\"loadfrom\"] \n",
    "                params[\"rcv_file\"] = val[\"loadfrom\"]\n",
    "            params[\"stitch_weight_delta\"] = stitch_weight_delta\n",
    "            params[\"stitch_bias_delta\"] = stitch_bias_delta        \n",
    "            params[\"stitch_weight_number\"] = stitch_weight_number\n",
    "            params[\"stitch_bias_number\"] = stitch_bias_number\n",
    "            params[\"my_acc\"] = acc\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                layers, features, handles = install_hooks(model_stitched)\n",
    "                \n",
    "                metrics = evaluate_model(model_stitched, dl, 'acc', verbose=2, device=device)\n",
    "                params.update(metrics)\n",
    "                classes = None\n",
    "                df = perform_analysis(features, classes, layers, params, n=0)\n",
    "                df.to_csv(f\"{outpath}\")\n",
    "                \n",
    "            for h in handles:\n",
    "                h.remove()\n",
    "            del model_stitched, layers, features, metrics, params, df, handles\n",
    "            gc.collect()\n",
    "        else:\n",
    "            dl = TDL\n",
    "            \n",
    "            print(f\"output to {outpath}\")\n",
    "                    \n",
    "            params = {}\n",
    "            params[\"model\"] = model_training_type\n",
    "            params[\"dataset\"] = dataset_type\n",
    "            params[\"seed\"] = seed\n",
    "            if val[\"train\"]: # as only one network used, record its filename as both send and receive files\n",
    "                params[\"send_file\"] = val[\"saveas\"] \n",
    "                params[\"rcv_file\"] = val[\"saveas\"] \n",
    "            else:    \n",
    "                params[\"send_file\"] = val[\"loadfrom\"] \n",
    "                params[\"rcv_file\"] = val[\"loadfrom\"]\n",
    "            params[\"val_acc\"] = acc / 100\n",
    "            params[\"name\"] = \"only\"\n",
    "    \n",
    "            results = []\n",
    "            results.append(params)\n",
    "            df = pd.DataFrame.from_records(results)\n",
    "            df.to_csv(f\"{outpath}\")\n",
    "                        \n",
    "            del  params, df\n",
    "            gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b388249-6105-4382-be3f-e8b5c9678479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in stitch weights: 13.04896354675293\n",
      "Largest abs weight change: 0.06711113452911377\n",
      "Number of weights changing > 0.1 of that: 222210\n",
      "13.04896354675293\n",
      "222210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stitch_weight_diff = trained_stitch_weight - initial_stitch_weight\n",
    "stitch_weight_delta = torch.linalg.norm(stitch_weight_diff).item()\n",
    "print(f\"Change in stitch weights: {stitch_weight_delta}\")\n",
    "maxabsweight =  torch.max(stitch_weight_diff.abs()).item()\n",
    "print(f\"Largest abs weight change: {maxabsweight}\")\n",
    "stitch_weight_number = torch.sum(torch.where(stitch_weight_diff.abs() > 0.1*maxabsweight, True, False)).item()\n",
    "print(f\"Number of weights changing > 0.1 of that: {stitch_weight_number}\")\n",
    "\n",
    "print(stitch_weight_delta)\n",
    "print(stitch_weight_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db5808a-6351-4133-9e7c-85e8e9248cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stitching_accuracies={'randinit': {1: 98.38, 8: 97.93, 22: 93.37, 29: 90.52, 35: 89.37}, 'unbias': {1: 98.41, 8: 98.29, 22: 98.21, 29: 98.48, 35: 98.47}}\n",
      "stitching_penalties={'randinit': {1: -88.06, 8: -87.61000000000001, 22: -83.05000000000001, 29: -80.19999999999999, 35: -79.05000000000001}, 'unbias': {1: -0.09000000000000341, 8: 0.029999999999986926, 22: 0.10999999999999943, 29: -0.1600000000000108, 35: -0.15000000000000568}}\n"
     ]
    }
   ],
   "source": [
    "logtofile(f\"{stitching_accuracies=}\")\n",
    "logtofile(f\"{stitching_penalties=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd669a19-7c42-4265-b8e8-57165995c097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randinit-unbias\n",
      "original_accuracy[s_key]=10.32\n",
      "Stitch Accuracy\n",
      "L1: 98.38\n",
      "L8: 97.93\n",
      "L22: 93.37\n",
      "L29: 90.52\n",
      "L35: 89.37\n",
      "--------------------------\n",
      "unbias-unbias\n",
      "original_accuracy[s_key]=98.32\n",
      "Stitch Accuracy\n",
      "L1: 98.41\n",
      "L8: 98.29\n",
      "L22: 98.21\n",
      "L29: 98.48\n",
      "L35: 98.47\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for s_key in stitching_accuracies:        \n",
    "    logtofile(f\"{s_key}-unbias\")\n",
    "    logtofile(f\"{original_accuracy[s_key]=}\")\n",
    "    logtofile(\"Stitch Accuracy\")\n",
    "    for layer in stitching_accuracies[s_key]:\n",
    "        logtofile(f\"L{layer}: {stitching_accuracies[s_key][layer]}\")\n",
    "    logtofile(\"--------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
